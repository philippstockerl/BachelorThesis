\documentclass[12pt,a4paper]{report}

\usepackage{geometry}
\geometry{
  a4paper,
  left=30mm,
  right=25mm,
  top=25mm,
  bottom=30mm
}
% Clean, blocky chapter headings
\usepackage{titlesec}

% Chapter label styling (CHAPTER ONE)
\newcommand{\chaplabel}{\bfseries\large\MakeUppercase{Chapter \thechapter}}
\newcommand{\chaplabelstar}{\bfseries\large\MakeUppercase{Chapter}}

\titleformat{\chapter}[display]
  {\bfseries}                % overall font for the block
  {\chaplabel}               % left-aligned label
  {1ex}                      % space between label and rule/title
  {\titlerule[2pt]\vspace{1ex}\Huge\bfseries\MakeUppercase} % rule + big title
  []                         % no extra after-title code

% Spacing: no top skip, some breathing room before text
\titlespacing*{\chapter}{0pt}{0pt}{3ex}

% Custom style for unnumbered chapters (e.g., Lists, Abbreviations)
\makeatletter
\renewcommand{\@schapter}[1]{%
  \if@openright\cleardoublepage\else\clearpage\fi
  \thispagestyle{plain}%
  {\bfseries\large\MakeUppercase{#1}\par\vspace{0.5ex}\titlerule[2pt]\vspace{1ex}}%
}
\makeatother

\titleformat{\section}
  {\normalfont\Large\bfseries}
  {\thesection}{1em}{}
  [\titlerule]
\titlespacing*{\section}{0pt}{1.2\baselineskip}{0.6\baselineskip}


\titlespacing*{\subsection}{0pt}{10pt}{4pt}

% Numbering style: use hyphen instead of dot (e.g., 2-1, 2-2-1)
\renewcommand{\thesection}{\thechapter-\arabic{section}}
\renewcommand{\thesubsection}{\thesection-\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection-\arabic{subsubsection}}

% SUBSUBSECTION
\titleformat{\subsubsection}
  {\normalfont\bfseries\small}
  {\thesubsubsection}
  {1em}
  {}

\titlespacing*{\subsubsection}{0pt}{8pt}{3pt}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage[table]{xcolor}
\usepackage{colortbl}
\usepackage{lmodern}
\setlength{\parindent}{1.5em}
\setlength{\parskip}{0.5\baselineskip}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{array}
\usepackage{amsmath, amssymb}
\usepackage{empheq}
\usepackage[font=footnotesize,labelfont=bf,textfont=it]{caption}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{placeins}
\usepackage{multirow}

\usetikzlibrary{
  arrows.meta, 
  positioning, 
  decorations.pathreplacing,
  shapes.geometric}
\usepackage{mdframed}
\usepackage{amsthm}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{axiom}{Axiom}[chapter]

\theoremstyle{definition}
\newtheorem{distinction}{Distinction}[chapter]
\usepackage{subcaption}
\usepackage{longtable}
\usepackage{fmtcount}   % spell chapter numbers (one, two, ...)
\usepackage{titletoc}   % custom ToC layout
\usepackage[scaled=0.96]{helvet} % Helvetica-like sans for headings/ToC
\setstretch{1.15}

% -------------------------------------------------------
% TABLE OF CONTENTS styling (CHAPTER ONE / TITLE look)
% -------------------------------------------------------
\renewcommand{\contentsname}{\MakeUppercase{Table Of Contents}}

% ToC heading appearance
\titlecontents{chapter}
  [0pt]
  {\addvspace{1.2em}\bfseries}
  {\bfseries CHAPTER \MakeUppercase{\thecontentslabel}%
   \titlerule*[0.6em]{.}\contentspage\\[-0.2ex]%
   \bfseries\MakeUppercase}
  {\bfseries\MakeUppercase}
  {}[\vspace{0.6em}]

\titlecontents{section}
  [1.5em]
  {\rmfamily}
  {\contentslabel{2.0em}}
  {}
  {\titlerule*[0.6em]{.}\contentspage}

\titlecontents{subsection}
  [3.0em]
  {\rmfamily}
  {\contentslabel{2.4em}}
  {}
  {\titlerule*[0.6em]{.}\contentspage}

\titlecontents{subsubsection}
  [4.2em]
  {\rmfamily}
  {\contentslabel{3.0em}}
  {}
  {\titlerule*[0.6em]{.}\contentspage}

% Section-style headings for ToC/LoF/LoT (match ABSTRACT/Notation)
\makeatletter
\newcommand{\sectiontoc}{%
  \section*{\contentsname}%
  \@starttoc{toc}%
}
\newcommand{\sectionlot}{%
  \section*{\listtablename}%
  \addcontentsline{toc}{section}{\listtablename}%
  \@starttoc{lot}%
}
\newcommand{\sectionlof}{%
  \section*{\listfigurename}%
  \addcontentsline{toc}{section}{\listfigurename}%
  \@starttoc{lof}%
}
\makeatother

\newcommand{\uparrowmark}{%
  \tikz[baseline=-0.5ex] \draw[->, line width=1pt, red] (0,-1ex) -- (0,1ex);
}

\newcommand{\downarrowmark}{%
  \tikz[baseline=-0.5ex] \draw[->, line width=1pt, green!70!black] (0,1ex) -- (0,-1ex);
}


\begin{document}
\thispagestyle{empty}

% -------------------------------------------------------
% LOGO + UNIVERSITY block
% -------------------------------------------------------

\begin{center}

\includegraphics[height=3cm]{figs/LogoBlack.png}\\[1.5cm]

{\Large \textsc{Faculty of Business, Economics and Information Systems}}\\[3pt]
{\large \textsc{University of Passau}}\\[2cm]

{\large \textsc{BACHELOR THESIS}}\\[1.8cm]

{\LARGE Philipp Stockerl}\\
[1cm]
\hrule
\vspace{0.5cm}
{\Huge \bfseries Robust and Adaptive
Path Planning for Autonomous Vehicles
in Spatio-Temporal Cost Fields}\\[1cm]

\end{center}


\hrule
\vspace{0.2cm}
% Institution block
\begin{center}
Chair of \\[1em]
Business Decisions \&\ Data Science\\
Business and Economics Focus Management Science\\
Operations and Supply Chain Management
\end{center}

\vspace{1cm}

\begin{flushleft}
\begin{tabular}{rl}
Supervisor of the Thesis:  & Prof. Dr. Marc Goerigk \\
Double Bachelor Programmes: &
\begin{tabular}[t]{@{}l@{}}
Business Administration and Economics,\\
Information Systems
\end{tabular}
\end{tabular}
\end{flushleft}

\vfill

\begin{center}
Passau, 23.01.2025\\[3mm]
\end{center}

\clearpage


% =======================================================
% INFORMATION + ABSTRACT page
% =======================================================

\renewcommand{\thepage}{\roman{page}}

\section*{INFORMATION}
\begin{tabular}{rl}
\textbf{Title:} & Robust and Adaptive Path Planning for Autonomous Vehicles\\
& in Spatio-Temporal Cost Fields \\
\textbf{Author:} & Philipp Stockerl\\
\textbf{Institute:} & Chair of Business Decisions \&\ Data Science,\\
& Business and Economics Focus Management Science/ \\
& Operations and Supply Chain Management\\
\textbf{Supervisor:} & Prof. Dr. Marc Goerigk\\
\textbf{Keywords:} & Optimization, Management Science \\ 
 & Geostatistics, Modelling,\\ 
 & Optimization under Uncertainty, \\ 
 & Robotics, Path Planning
\end{tabular}

\vspace{1.5cm}




\section*{ABSTRACT}
This thesis investigates minimum-cost path planning in spatio-temporal environments under uncertain edge costs.
Our testbed is mobile-robot routing on directed graphs, with edge costs generated from synthetic spatio-temporal random fields via geostatistical methods. 
We compare two complementary approaches: (i) robust combinatorial optimization models for shortest paths, and (ii) an incremental shortest path heuristic that adapts after costs change. 
We address uncertainty both ex-ante (before executing a path) and ex-post (after cost shifts).
We evaluate three options drawn from these two approaches and use the results to answer the research objectives and questions.
Our research shows that...

\vfill

{\footnotesize
Typeset with \LaTeX. Copyright © 2026 Philipp Stockerl.
\\
This work has been produced in coordination with the University of Passau.
}


\clearpage
\pagenumbering{roman}
\sectiontoc
\clearpage
\pagenumbering{arabic}
\newpage

\section*{Notation}
\addcontentsline{toc}{section}{Notation}
\begin{longtable}{p{0.26\textwidth} p{0.68\textwidth}}
\toprule
\textbf{Symbol} & \textbf{Description} \\
\midrule
\endfirsthead
\toprule
\textbf{Symbol} & \textbf{Description} \\
\midrule
\endhead
\midrule
\multicolumn{2}{r}{\textit{Continued on next page}}\\
\endfoot
\bottomrule
\endlastfoot
\multicolumn{2}{c}{\textbf{Graphs and paths}}\\[0.1cm]
$G=(V,E)$ & Directed graph; $(V,E)$ notation used in robust models. \\
$G=(S,E)$ & Directed graph; $(S,E)$ notation used in D* Lite.\\
$V$, $S$ & Vertex sets (robust optimization vs. D* Lite grid cells). \\
$E$ & Set of directed edges (arcs). \\
$i,j$ & Node indices for edge endpoints $(i,j) \in E$. \\
$s,t$ & Start and target nodes in robust models. \\
$s_{\text{start}},\,s_{\text{goal}}$ & Current start and goal vertices in D* Lite. \\
$\delta^+(\cdot)$, $\delta^-(\cdot)$ & Successor and predecessor edge sets. \\
$\mathcal{X}$ & Solution set (of feasible $s$--$t$ paths). \\
$x_e$ & Binary decision variable indicating whether edge $e$ is used. \\
$L_{\min}$ & Minimum number of edges on an $s$--$t$ path (4-connected grid). \\
\midrule
\multicolumn{2}{c}{\textbf{Scenarios and costs}}\\[0.1cm]
$\Omega$, $\omega$ & Scenario index set and index. \\
$\mathcal{T}$, $\tau$ & Time index set and time index for STRF slices. \\
$|\Omega|$, $|\mathcal{T}|$ & Number of scenarios and time steps. \\
$c_e^{\omega}$ & Cost of edge $e$ in scenario $\omega$. \\
$c(i,j)$ & Traversal cost of edge $(i,j)$ in the current scenario (D* Lite). \\
$\mathbf{c}^{\omega}$ & Scenario cost vector. \\
$f_{\tau}(p,q)$ & Scenario cost surface at time $\tau$. \\
$Z(p,q,\tau)$ & Spatio-temporal random field value. \\
\midrule
\multicolumn{2}{c}{\textbf{Discrete robust model}}\\[0.1cm]
$z$ & Worst-case path cost (discrete min--max model). \\
\midrule
\multicolumn{2}{c}{\textbf{Budgeted uncertainty model}}\\
$\underline{c}_e$ & Nominal (average) edge cost. \\
$d_e$ & Maximum deviation from nominal cost. \\
$\Gamma$ & Budget of uncertainty. \\
$\pi$ & Dual variable for the budget constraint. \\
$\rho_e$ & Auxiliary deviation variable for edge $e$. \\
$\lambda$ & Normalized budget factor, $\Gamma(\lambda) = \lambda \Gamma_{\max}$. \\
$\Gamma_{\max}$ & Maximum budget, typically set to $L_{\min}$. \\
\midrule
\newpage
\multicolumn{2}{c}{\textbf{D* Lite}}\\
$g(s)$ & Current shortest-path cost estimate from $s$ to $s_{\text{goal}}$. \\
$\mathrm{rhs}(s)$ & One-step lookahead cost-to-go from $s$. \\
$h(i,j)$ & Admissible heuristic estimate between vertices; also used as a metric distance in the geostatistical model (context by arguments). \\
$k(s)=(k_1(s),k_2(s))$ & Lexicographic priority key for vertex $s$. \\
$k_m$ & Heuristic shift variable due to start-vertex movement. \\
$U$ & Priority queue of locally inconsistent vertices. \\
$u$ & Vertex selected from $U$ for expansion. \\
$\textit{ComputeShortestPath}()$ & Procedure that restores local consistency. \\
$\textit{UpdateVertex}(s)$ & Procedure that updates $\mathrm{rhs}(s)$ and queue membership. \\
\midrule
\multicolumn{2}{c}{\textbf{Geostatistical/SRF model}}\\
$\mathbf{x}=(p,q,\tau)$ & Coordinate vector in the 3D space--time domain. \\
$p,q$ & Spatial coordinates along the x- and y-axes. \\
$N_p,\,N_q$ & Grid dimensions in the spatial axes. \\
$\Delta p,\,\Delta q,\,\Delta \tau$ & Coordinate increments in space and time. \\
$\ell_p,\,\ell_q,\,\ell_t$ & Spatial and temporal correlation lengths. \\
$a_p,\,a_q,\,a_t$ & Anisotropy ratios. \\
$\sigma^2$ & Field variance. \\
$\alpha$ & Stable-kernel exponent; also spatial scaling factor in experiments (context disambiguates). \\
$\beta$ & Temporal scaling factor. \\
$\nu$ & Mat\'ern smoothness parameter. \\
$\mathbf{k}_i$ & Wave vectors in the spectral construction. \\
$Z_{1,i}, Z_{2,i}$ & Standard normal coefficients in the spectral method. \\
$\gamma(r)$, $C(\cdot)$, $\rho(\cdot)$ & Semi-variogram, covariance, and correlation functions. \\
\end{longtable}
\clearpage


\sectionlot
\clearpage


\sectionlof
\clearpage

\chapter{INTRODUCTION}
\vspace{1cm}

  \paragraph{Problem Setting}
    Autonomous vehicle navigation admits a wide range of planning formulations, ranging from
    global route planning to local reactive control and hybrid approaches that combine multiple
    decision layers \cite{katona2024,abdulsaheb2023}.
    Depending on the application, planners optimize objectives such as travel time, energy
    consumption, risk exposure, or mission goals under kinematic, safety, and environmental
    constraints \cite{aitsaadi2022,gugan2023,zafar2018}.
    Despite this diversity, many planning algorithms share a common structural core: they
    evaluate feasible paths on graph-based representations under additive cost models.

    From a methodological perspective, these formulations can be viewed as instances of
    combinatorial optimization problems (COP) studied in operations research (OR).
    The shortest-path problem (SPP) provides the most elementary abstraction of this core and
    underlies a wide range of planning algorithms, including heuristic search, dynamic
    programming, and network flow formulations \cite{wu2025,goerigk2024,qin2023}.
    Even when planning problems extend beyond single-pair routing—for example, through timing
    constraints, risk measures, or vehicle dynamics—their algorithmic structure often still
    relies on modified shortest-path computations.

    \begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-0.6cm}
    \centering
    \includegraphics[width=\linewidth]{figs/PassauWeatherMapSensor.png}
    \caption{Spatial environmental data with sensor locations and inferred wind intensity
    over a two-dimensional domain.}
    \label{fig:weather-radar}
    \end{wrapfigure}

    In real-world navigation tasks, however, the nominal assumptions of the classical SPP no
    longer hold.
    Traversal costs vary across space and time and are only partially observable at planning
    time.
    In unmanned aerial vehicle (UAV) applications, for instance, costs depend on environmental
    conditions such as wind fields, which directly affect travel time and operational risk along
    flight segments \cite{roytvandghiasvand2024}.
    Forecasts and sensor data provide partial information, but future realizations remain
    uncertain and deviations from nominal predictions are unavoidable.
        \clearpage

    Figure~\ref{fig:weather-radar} shows how heterogeneous environmental information can be
    aggregated into spatial cost fields that serve as inputs to routing decisions.
    As costs evolve over time, the relative attractiveness of feasible paths changes rather than
    being blocked entirely \cite{azizi2024}, such that planning decisions based solely on nominal
    information may perform poorly or even fail.
    Figure~\ref{fig:spatio-temporal-routing-example} illustrates this effect by showing spatial
    cost realizations at two different time points over an identical graph structure.
    This motivates extensions of the classical shortest-path problem that explicitly account
    for uncertainty and temporal dynamics in traversal costs.

    \begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.5\textwidth}
      \includegraphics[width=\linewidth]{figs/HighLevelT1.png}
      \caption{Time $t$}  
    \end{subfigure}\hfill
    \begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\linewidth]{figs/HighLevelT2.png}
      \caption{Later time $t+n$}
  \end{subfigure}\hfill
    \caption{Spatial cost realizations at two different time points over a fixed graph topology.}
    \label{fig:spatio-temporal-routing-example}
  \end{figure}

  Two dominant paradigms address shortest-path planning under such uncertainty by extending
  the classical model in fundamentally different ways:

  \textit{Robust optimization (RO)} addresses uncertainty \textit{ex ante} by selecting complete
  paths prior to execution and protecting them against adverse cost realizations within
  explicitly defined uncertainty sets.
  Robust combinatorial shortest-path formulations optimize the worst-case path cost over such
  sets and increasingly derive uncertainty sets from data rather than expert choice \cite{chassein2019,goerigk2025}.
  This approach adopts a global, strategic perspective on uncertainty and is particularly
  suited to planning problems in which route decisions must be fixed before execution and
  robust performance guarantees are required.
  Prominent application areas include vehicle routing problems (VRPs), where robustness is
  used to model application-specific uncertainty \cite{roytvandghiasvand2024,zhang2023,yu2023}.
  Further extensions incorporate time-dependent decision making at multiple planning levels
  \cite{goerigk2021,zhang2022} and address scalability challenges arising from large data sets
  \cite{wu2025}.
  Evaluation in this literature typically relies on scenario-based or bounded-deviation
  constructions to compare robustness across alternative formulations \cite{chassein2019}.
  These models provide the ex-ante reference solutions used for comparison in this work.

  \textit{Incremental search-based planning} addresses uncertainty \textit{ex post} by revealing
  cost information during execution and repairing paths locally as changes occur.
  These methods build on classical shortest-path and heuristic search principles, most notably
  Dijkstra’s algorithm \cite{dijkstra1959} and A* \cite{hart1968}, and extend them to dynamic
  environments through algorithms such as D* \cite{stentz1994}, LPA* \cite{koenig2004}, and
  D* Lite \cite{koenig2002}.
  By reusing previous search effort, incremental planners avoid full recomputation and enable
  efficient replanning when edge costs change \cite{bagad2024}.
  Recent research focuses on refining these foundations to improve replanning efficiency, path
  quality, and robustness under frequent cost updates, for example by incorporating safety
  margins, kinematic constraints, or adaptive heuristics
  \cite{wang2021,wang2022,he2024,li2024,xu2025}.
  As a result, incremental search produces globally consistent paths while emphasizing
  execution-time adaptivity in dynamic and partially known environments \cite{karur2021}.
  This paradigm is therefore particularly well suited to mobile robotic systems, where tight
  integration with onboard sensing and frequent environment updates is required.

  In essence, robust optimization emphasizes strategic, global path planning by selecting a
  complete route at planning time and protecting it against worst-case cost realizations,
  often assuming centralized computation and limited adaptivity during execution.
  Incremental search-based methods likewise aim to compute globally consistent paths, but rely
  on locally grounded exploration and adaptation, trading increased online computation for
  the ability to react to newly revealed cost information.
  Although both paradigms address the same underlying routing task, they differ fundamentally
  in their information assumptions, degree of adaptivity, and evaluation criteria.

  \paragraph{Research Objective}
  The objective of this thesis is to develop and apply a controlled experimental framework
  that enables systematic comparisons between ex-ante robust planning and ex-post adaptive
  search under identical spatio-temporal uncertainty realizations. In addition, the thesis
  explores a hybrid planning approach in which robust optimization provides global, ex-ante
  guidance, while incremental search contributes local, ex-post adaptation during execution.
  Using this framework, we conduct a systematic experimental comparison of selected
  robust shortest-path formulations and an incremental replanning method under
  spatio-temporal cost uncertainty. Performance is evaluated with respect to solution
  quality, computational effort, and execution-time adaptivity in order to assess the
  practical implications of each paradigm for autonomous vehicle guidance.

  \paragraph{Motivation}
  A key motivation for this objective is that, despite extensive research in robust
  optimization and incremental search, there is little controlled, head-to-head comparison
  of these approaches under shared experimental conditions. Robust shortest-path
  formulations and incremental search methods are typically studied in isolation and rarely
  evaluated on identical graph structures, common spatio-temporal cost realizations, and
  comparable performance metrics. This lack of a unified experimental setting limits our
  understanding of their relative strengths, weaknesses, and practical trade-offs for
  autonomous vehicle guidance on the same underlying cost fields.

  Related work exists in global--local planning frameworks that combine long-horizon
  planning with local reactive control \cite{gao2024,lu2025}. These methods typically
  decompose planning into a hierarchical structure, where a global planner computes a
  reference path and a local controller handles short-term disturbances and obstacle
  avoidance. While effective in practice, such approaches primarily focus on architectural
  integration and performance improvements within a single paradigm. Consequently,
  they do not provide a controlled comparison between ex-ante robustness and ex-post
  adaptivity under a common problem formulation, uncertainty model, and evaluation
  protocol.



  \paragraph{Contribution}
  The contributions of this thesis are fourfold:
  (i) the design of a reproducible experimental framework that enforces shared data,
  graph structures, and evaluation metrics across planning algorithms;
  (ii) a spatio-temporal cost generation process based on geostatistical random fields that
  are mapped consistently onto routing graphs;
  (iii) implementations of robust and incremental planning methods, including a hybrid
  guidance variant that combines ex-ante protection with ex-post adaptation; and
  (iv) a unified evaluation protocol for comparing solution cost, computational effort,
  and execution-time adaptivity.
  The experimental framework is implemented as a conceptual decision support system (DSS)
  that integrates spatio-temporal cost generation, robust combinatorial optimization models,
  and incremental search-based planning methods into a unified pipeline
  (Figure~\ref{fig:topdown-architecture-DSS}).

  \vspace{0.4cm}
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figs/TopDownArchitecture.png}
    \caption{Top-down architecture of the conceptual decision support system used for experimental
    comparison, integrating spatio-temporal cost generation, robust optimization, incremental
    search-based planning, and a hybrid guidance variant within a unified pipeline.}
    \label{fig:topdown-architecture-DSS}
  \end{figure}

    

\chapter{CONCEPTUAL FOUNDATIONS}
\label{chap:conceptual-foundations}
\section{Model and Data Driven \newline Decision Support Systems}
Decision Support Systems (DSS) are interactive, computer-based systems that support
decision-making in complex and uncertain environments by integrating data, analytical
models in user interfaces \cite{fernando2022}. Rather than automating decisions, DSS structure
decision-making by making assumptions explicit and enabling systematic comparison of
alternatives.

At a functional level, DSS link data with analytical models. Input data are processed and
transformed before being evaluated by models that represent the underlying decision
problem. The resulting outputs---such as costs, feasibility indicators, or performance
measures---are interpreted through visualization and interaction, forming the basis for
model-driven decision support \cite{power2002}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{figs/BasicDSSArchitectureNew.png}
  \caption{Basic architecture of a model-driven decision support system}
  \label{fig:basic-dss-architecture}
\end{figure}

\paragraph{DSS for Vehicle Routing}
Vehicle routing constitutes a prominent application area for decision support systems \cite{ruiz2004,lacomme2021}.
Routing decisions require selecting efficient paths while accounting for operational
constraints, uncertain travel times, and dynamic environmental conditions. As a result,
vehicle routing DSS naturally integrate multiple analytical components.

A central role is played by model-driven DSS \cite{power2007}, which rely on formal models to represent
routing decisions and evaluate alternatives. Such systems may incorporate deterministic
optimization models, robust optimization models \cite{gounaris2016}, heuristic algorithms, or simulation-based
approaches \cite{fanti2015}. Decision variables typically correspond to route choices or planning
parameters, while performance measures include total cost, robustness, or computational
effort. Environmental conditions act as exogenous inputs that influence outcomes but
cannot be directly controlled.

Vehicle routing DSS often exhibit a strong data-driven component. When routing decisions
depend on geographic or spatial information, this leads naturally to spatial DSS \cite{keenan1998}, which
integrate geographic representations such as maps or spatial cost fields. These
representations enable decision makers to interpret routing decisions in their geographic
context and to relate analytical results to real-world environments \cite{ulmer2017}. In this thesis,
spatial DSS concepts are combined with model-driven DSS to address routing problems under
spatio-temporal uncertainty.

\paragraph{Model and Data Utilization}
The effectiveness of a DSS depends critically on the models and data it employs. Data
quality, aggregation, and normalization directly influence the reliability of
decision-relevant information, while the choice of analytical models determines which
aspects of the decision problem can be analyzed and optimized.
We employ a conceptual DSS for our autonomous vehicle routing problem as an interactive control surface
that embeds a data component and model components.

\section{Data Component: \newline Geostatistical Data Generation}
\label{sec:data-component}
For the data component of our conceptual framework, we generate spatio-temporally correlated cost fields using geostatistical methods. These fields serve as controlled, reproducible inputs to all shortest-path models evaluated in this work. Since geostatistics is used purely as a data generation tool, we focus on implementation-relevant design choices rather than a detailed statistical treatment.

Using simulated data for model comparison is common practice when real-world data is scarce or difficult to control experimentally \cite{matsypura2026,meng2025}. Geostatistical frameworks provide a principled way to generate spatially and temporally correlated synthetic data while maintaining full control over variance, correlation length, and anisotropy \cite{muller2022}. In particular, we rely on the GSTools library, which offers reproducible implementations of second-order random field models widely used in simulation studies \cite{raimbault2019}.

We model cost fields as realizations of a weakly stationary Gaussian random field defined on a three-dimensional space–time domain. Spatial and temporal dependence are introduced via a parametric covariance function, whose structure is fully determined by a normalized correlation kernel and a metric distance. Time is treated as an additional geometric dimension, resulting in temporally consistent spatial slices rather than independent scenarios.

GSTools provides a family of admissible correlation kernels with varying smoothness and compact support properties (see Table~\ref{tab:gstools-covariance-models}). While kernel choice influences local regularity, all kernels share a common structure in which dependence is governed by a single scalar distance. Directional anisotropy and spatio-temporal coupling are incorporated by defining this distance through a weighted metric.

Figure~\ref{fig:two-by-four-kernels} illustrates the qualitative effect of different kernel choices under identical parameters. These visualizations demonstrate that kernel selection alone can induce substantially different spatial roughness, despite identical variance and correlation length. We further discuss kernel selection in Chapter~4.

\begin{figure}[htbp]
\centering
\begin{subfigure}{0.23\textwidth}
  \includegraphics[width=\linewidth]{figs/GaussianKernel.png}
  \caption{Gaussian}
\end{subfigure}\hfill
\begin{subfigure}{0.23\textwidth}
  \includegraphics[width=\linewidth]{figs/CubicKernel.png}
  \caption{Cubic}
\end{subfigure}\hfill
\begin{subfigure}{0.23\textwidth}
  \includegraphics[width=\linewidth]{figs/ExponentialKernel.png}
  \caption{Exponential}
\end{subfigure}\hfill
\begin{subfigure}{0.23\textwidth}
  \includegraphics[width=\linewidth]{figs/CircularKernel.png}
  \caption{Circular}
\end{subfigure}

\medskip

  \begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{figs/Gaussian3D.png}
    \caption{Gaussian 3D}
      \end{subfigure}\hfill
      \begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{figs/Cubic3D.png}
    \caption{Cubic 3D}
  \end{subfigure}\hfill
    \begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{figs/Exponential3D.png}
    \caption{Exponential 3D}
  \end{subfigure}\hfill
    \begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{figs/Circular3D.png}
    \caption{Circular 3D}
  \end{subfigure}

\caption{Difference of covariance models for same parameters visualized}
\label{fig:two-by-four-kernels}
\end{figure}




The resulting spatio-temporal random fields constitute the data-generating basis for all experiments. Each temporal slice represents a spatial cost realization, and temporal correlation ensures consistency across scenarios. By discretizing spatial slices into directed graphs, the continuous geostatistical model is transformed into time-indexed shortest-path instances, enabling a controlled comparison of robust and adaptive planning methods under identical uncertainty assumptions

\section{Model Component: \newline Shortest-Path Planning Under Uncertainty}
\label{sec:shortest-path-planning-under-uncertainty}
This section establishes a common problem formulation for shortest-path planning that
serves as a conceptual foundation for the two planning paradigms studied in this thesis.
It serves as a backbone for the model component of our conceptual DSS.
We begin with the classical shortest-path problem under nominal assumptions and then
introduce cost uncertainty, highlighting how violations of these assumptions lead to
fundamentally different planning logics.

Although both paradigms introduced in the introduction address the same underlying routing problem on an identical graph
structure, they differ in how this problem is represented and solved.
Following the taxonomy of Hart et al.~\cite{hart1968}, we distinguish between
optimization-based formulations and heuristic search--based methods as two complementary
perspectives on shortest-path planning.
This distinction provides the organizing lens for the remainder of this chapter.

\paragraph{Shortest-path problem formulation}
We consider a directed graph $G=(V,A)$, where $V$ denotes the set of vertices and
$A \subseteq V \times V$ the set of directed arcs.
Each arc $e=(i,j)\in A$ is associated with a nonnegative traversal cost $c_e$.
A path $P$ from a start vertex $s\in V$ to a destination vertex $t\in V$ is defined
as an ordered sequence of arcs connecting $s$ to $t$.
The single-pair shortest-path problem (SPSP) consists of finding a path
$P^\star$ that minimizes the total path cost
\[
C(P) = \sum_{e \in P} c_e .
\]
Such graph structures naturally represent spatial or spatio-temporal cost fields derived
from simulated or real-world data (Figures~\ref{fig:weather-radar} and
\ref{fig:spatio-temporal-routing-example}).
The shortest-path problem is inherently combinatorial, as it requires selecting a feasible
sequence of discrete arcs from a finite set.

\paragraph{Nominal shortest-path problem}
In the classical (nominal) setting, traversal costs are assumed to be nonnegative,
time-invariant, and fully known at planning time.
Under these assumptions, both optimization-based and heuristic search--based approaches
solve the same underlying combinatorial problem and are equivalent with respect to
optimality, differing only in representation and solution strategy.

\vspace{0.2cm}
From an \emph{optimization perspective}, the shortest-path problem is treated as a combinatorial
optimization problem in which arcs constitute the ground set of decision elements.
Following the general framework of combinatorial optimization~\cite{goerigk2024}, let
$S = A$ denote the finite ground set of directed arcs.
Each arc $e \in A$ is associated with a nonnegative cost $c_e$, and a feasible solution
corresponds to selecting a subset of arcs that forms an $s$--$t$ path.
Using binary decision variables $x_e \in \{0,1\}$ to signal wether a edge is selected or not,
the nominal shortest-path problem can be formulated as

      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Nominal Combinatorial Shortest-Path Problem}
      \begin{empheq}{align}
      \min \quad & \sum_{e \in A} c_e x_e \\
      \text{s.t.} \quad
      & \sum_{(i,j)\in A} x_{ij} - \sum_{(j,i)\in A} x_{ji} = b_i
      && \forall i \in V, 
            \label{eq:flow-balance-constraint}
      \\
      & x_e \in \{0,1\}
      && \forall e \in A,
      \label{eq:nominal-combinatorial-shortest-path}
      \end{empheq}
      \end{mdframed}
where $b_s = 1$, $b_t = -1$, and $b_i = 0$ for all
$i \in V \setminus \{s,t\}$.
The flow-balance constraints (2.2) define the feasible set
$\mathcal{X} \subseteq \{0,1\}^{|A|}$ and encode the combinatorial structure of valid
$s$--$t$ paths.
Under nonnegative costs, any optimal solution corresponds to a simple path.

\vspace{0.2cm}
\emph{Heuristic search--based methods} provide an algorithmic counterpart to this formulation.
They interpret the graph as a discrete state space in which vertices represent states and
arcs represent transitions.
Paths are constructed implicitly through successive state expansions guided by cost
estimates and heuristic information, rather than by explicitly selecting edges.
The nominal shortest-path problem can equivalently be expressed as a discrete dynamic
programming problem.
Let $V^\star(v)$ denote the optimal cost-to-go from node $v$ to the destination $t$.
Under deterministic, time-invariant, and fully known arc costs, $V^\star$ satisfies
Bellman’s optimality equation

      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Bellman’s Optimality Equation}
      \begin{empheq}{align}
      V^\star(t) = 0, \qquad
      V^\star(v) = \min_{(v,u)\in A} \left\{ c_{vu} + V^\star(u) \right\}
      \quad \forall v \in V \setminus \{t\}.
      \end{empheq}
      \end{mdframed}
This recursion formalizes optimal substructure: every subpath of an optimal path is itself
optimal.
Heuristic search algorithms such as A* exploit this structure by constructing the optimal
path implicitly.
A* maintains cost-to-come estimates $g(v)$ and expands nodes in increasing order of
\[
f(v) = g(v) + h(v),
\]
where $h(v)$ is an admissible and consistent heuristic estimate of the remaining cost from
$v$ to $t$.
With an admissible, consistent heuristic, A* returns an optimal $s$--$t$ path.
Thus, under nominal assumptions, optimization-based formulations and heuristic search
methods solve the same combinatorial shortest-path problem and are equivalent with respect
to optimality. A* serves as the nominal baseline; incremental methods such as LPA* and
D* Lite reuse its heuristic structure and repair only affected nodes when edge costs
change, rather than replanning from scratch (Table~\ref{tab:differences}).

\vspace{0.4cm}
\begin{table}[htbp]
\centering
\small
\renewcommand{\arraystretch}{1.15} % more row height
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}p{3.2cm} *{3}{>{\raggedright\arraybackslash}X}}
\toprule
\textbf{Conceptual Dimension} 
& \textbf{Nominal Shortest Path} 
& \textbf{Ex-Ante Robust Optimization} 
& \textbf{Ex-Post Incremental Search} \\
\midrule
Cost information
& Deterministic, time-invariant, fully known
& Uncertain but bounded via uncertainty sets
& Revealed or updated during execution \\
Optimality principle
& Bellman optimality holds globally
& Bellman optimality generally fails under min--max objectives
& Local consistency enforced incrementally \\
Representation
& Explicit or implicit (equivalent)
& Explicit edge-based decision variables
& Implicit state-space exploration \\
Decision timing
& Single planning step
& Ex-ante path selection
& Continuous replanning \\
Response to cost changes
& Not applicable
& No adaptation unless re-solved
& Local repair \\
Primary objective
& Minimum total cost
& Worst-case protected cost
& Adaptivity and replanning efficiency \\
\bottomrule
\end{tabularx}
\caption{Conceptual distinctions between nominal shortest-path planning, ex-ante robust
optimization, and ex-post incremental search under cost uncertainty.}
\label{tab:differences}
\end{table}

\paragraph{Shortest-path planning under uncertainty}
In spatio-temporal routing environments, the nominal assumptions of time-invariant costs
and full information no longer hold.
We model uncertainty through time-varying traversal costs on a fixed graph.
Let $k \in \{1,\dots,T\}$ index discrete planning or execution steps, and let $c_e^k$ denote
the cost of arc $e$ at step $k$.
The cost vector $c^k = (c_e^k)_{e \in A}$ represents a realization of a
spatio-temporally correlated cost field.
Conditional on a realization, costs remain deterministic and nonnegative, but future
realizations are not known at planning time.
At the time a path is planned, only partial information about future cost realizations is
available, for example in the form of forecasts, bounds, or scenario samples.
Additional cost information may become available during execution.
Figure~\ref{fig:sp-under-uncertainty} illustrates how this uncertainty alters the decision
context relative to the nominal setting.
Uncertainty fundamentally affects the information structure and objective of the planning
problem.



See \cite{madkour2017,deo1984} for additional SPP taxonomy.
While each realized instance of the shortest-path problem satisfies Bellman’s optimality
principle individually, robust objectives may couple decisions across time or scenarios.
As a result, global optimal substructure need not hold with respect to the robust planning
objective, even though the underlying graph structure is unchanged.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{figs/ShortestPathUnderUncertainty.png}
\caption{Conceptual overview of the shortest-path problem under uncertainty.
The underlying graph structure remains fixed, while traversal costs evolve over time.
Robust combinatorial optimization and incremental search-based planning represent two
distinct responses to uncertainty within the same problem setting.}
\label{fig:sp-under-uncertainty}
\end{figure}

Two coherent planning paradigms emerge from this setting.
Ex-ante robust optimization selects paths before execution and protects them against
adverse cost realizations within prescribed uncertainty sets.
Ex-post incremental search-based planning, in contrast, interleaves planning and execution
by repairing paths locally as new cost information becomes available.


The following sections formalize these two paradigms in detail.
Section~\ref{sec:robust-combinatorial-optimization} introduces robust combinatorial
shortest-path models under ex-ante uncertainty, while
Section~\ref{sec:incremental-search-based-path-planning} presents incremental
search-based planning as an ex-post adaptive alternative.

\section{Robust Combinatorial Optimization}
  \label{sec:robust-combinatorial-optimization}
  Building on the nominal formulation for the
  shortest-path problem (Equation~\ref{eq:nominal-combinatorial-shortest-path}),
  we introduce uncertainty modeling and "robustify" our nominal problem.
  We refer generally to \cite{goerigk2024} for formulations in this section.

    \paragraph{Robust Optimization and the Min--Max Principle}
      In robust shortest-path planning, costs are assumed to lie in a prescribed uncertainty
      set $\mathcal{U}\subseteq\mathbb{R}_{\ge0}^{|E|}$, and the planner selects a feasible
      path before the adversary selects a realization from $\mathcal{U}$ that maximizes its
      cost.

      Formally, robust planning is based on the min--max criterion
      \[
      \min_{x\in\mathcal{X}} \; \max_{\mathbf{c}\in\mathcal{U}}
      \sum_{(i,j)\in E} c_{ij} x_{ij},
      \]
      where $\mathcal{X}$ denotes the set of feasible $s$--$t$ paths defined by the
      flow-balance constraints (\ref{eq:flow-balance-constraint}).
      This criterion guarantees worst-case protection against all cost realizations
      contained in $\mathcal{U}$.
      Alternative robustness concepts exist; in this thesis we adopt the min--max 
      formulation as a simple, widely used baseline for worst--case analysis.

      In the following paragraphs, we introduce the uncertainty models used in this thesis.
      Their integration into fully specified shortest-path formulations is deferred to the
      Implementation chapter, where implementation details are discussed as well.


    \paragraph{Uncertainty Sets}
      The uncertainty set $\mathcal{U}$ specifies which realizations of edge costs are
      considered plausible and directly determines the level of robustness and
      conservatism of the resulting solution.
      In the context of shortest-path planning, each component of a cost vector
      corresponds to a single directed edge of the underlying graph.

      In this thesis, uncertainty sets are constructed from the synthetic spatio-temporal
      random fields used throughout; each temporal slice yields a spatial cost scenario (\ref{sec:data-component}).
      Based on this representation, two complementary uncertainty models are derived and
      evaluated: discrete scenario-based uncertainty and continuous budgeted uncertainty.


    \paragraph{Discrete Uncertainty Sets}
      A discrete uncertainty set consists of a finite collection of cost scenarios
      \[
      \mathcal{U} = \{\mathbf{c}^{\omega} \mid \omega \in \Omega\},
      \]

      \begin{wrapfigure}[9]{r}{0.3\textwidth}
      \vspace{-1cm}
      \centering
      \includegraphics[width=\linewidth]{figs/DiscreteUncertaintySet.png}
      \caption{Geometric interpretation of a discrete uncertainty set in a cost space.}
      \label{fig:discrete-uncertainty-set-fig}
      \end{wrapfigure}

      where each vector $\mathbf{c}^{\omega}$ represents a complete realization of edge costs
      over the graph.

      As illustrated in Figure~\ref{fig:discrete-uncertainty-set-fig}, discrete uncertainty
      represents uncertainty through a finite set of cost vectors corresponding to complete
      scenario realizations.

      Discrete uncertainty arises directly from the spatio-temporal random field
      representation: each cost vector $\mathbf{c}^{\omega}$ is a temporal slice, so all
      edge costs within a scenario come from the same snapshot. 
      Thus, $|\Omega|$ equals the number of time steps, and robust
      optimization evaluates candidate paths against all temporal realizations.
    

      For discrete uncertainty sets, the min--max problem can be reformulated using an
      epigraph formulation:

      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Epigraph Reformulation for Discrete Uncertainty}
      \begin{empheq}{align}
      \min \quad & z \\
      \text{s.t.}\quad
      & z \ge \sum_{i \in [n]} c_i^{\omega} x_i && \forall \omega \in \Omega, \\
      & x \in \mathcal{X}.
      \end{empheq}
      \end{mdframed}
      This reformulation replaces the inner maximization by a finite set of linear
      constraints and yields a deterministic mixed-integer optimization problem.

      These modeling choices have important computational consequences.
      From a theoretical perspective, the discrete scenario-based min--max shortest-path
      problem is NP--hard in general, even when the nominal shortest-path problem is
      polynomially solvable. Hardness results already arise for small numbers of scenarios,
      and the problem becomes strongly NP--hard when the number of scenarios is part of the
      input \cite{yu1998,goerigk2024}. Although pseudopolynomial dynamic programming
      algorithms exist for fixed scenario counts \cite{aissi2009}, their runtime grows rapidly
      with the number of scenarios, which limits practical scalability.

      The size of the epigraph reformulation grows linearly with the number of scenarios.
      For a graph with $|E|$ edges, $|V|$ vertices, and $|\Omega|$ scenarios, the resulting
      mixed-integer formulation contains $O(|E|)$ binary variables, $O(|V|)$ flow constraints,
      one additional continuous epigraph variable $z$, and $O(|\Omega|)$ robust constraints.
      Equivalently, the overall model size scales as $O(|E| + |V| + |\Omega|)$.

      

    \paragraph{Continuous Budgeted Uncertainty Sets}
      Continuous budgeted uncertainty summarizes cost variation across scenarios via
      nominal costs and bounded deviations.

      Given nominal costs $\underline{c}_i$ and maximum deviations $d_i$, the budgeted
      uncertainty set restricts the total amount of deviation that may occur
      simultaneously across edges by means of a global budget parameter $\Gamma$.

      \begin{equation}
      \label{eq:budgeted-uncertainty-set}
      \mathcal{U}
      =
      \left\{
      \mathbf{c} \;\middle|\;
      c_i = \underline{c}_i + d_i \delta_i,\;
      0 \le \delta_i \le 1,\;
      \sum_{i \in [n]} \delta_i \le \Gamma
      \right\}.
      \end{equation}

                \begin{wrapfigure}[11]{r}{0.3\textwidth}
          \vspace{0cm}
          \centering
          \includegraphics[width=\linewidth]{figs/ContiniousBudgetedUncertaintySet.png}
          \caption{Geometric interpretation of a continuous budgeted uncertainty set in cost space.}
          \label{fig:budgeted-uncertainty-set-fig}
          \end{wrapfigure}
      In contrast to the discrete uncertainty set, the budgeted uncertainty set shown in Figure~\ref{fig:budgeted-uncertainty-set-fig}
      defines a continuous polyhedral region around a nominal cost vector, where the total
      deviation across edges is limited by the budget parameter $\Gamma$.


      For shortest-path planning, the budget parameter $\Gamma$ admits an intuitive
      interpretation.
      It bounds the number or aggregate magnitude of edges along a path whose costs are
      allowed to deviate from their nominal values at the same time.
      Varying $\Gamma$ interpolates between the nominal solution ($\Gamma = 0$) and full
      worst-case protection ($\Gamma \ge |E|$), yielding a controlled robustness--conservatism
      trade-off.

      Following standard duality arguments, the inner maximization problem can be
      dualized, yielding the following robust counterpart:

      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Robust Min--Max Formulation for Budgeted Uncertainty}
      \begin{empheq}{align}
      \min_{x,\,\pi,\,\boldsymbol{\rho}} \quad
      & \sum_{i \in [n]} \underline{c}_i x_i
        + \Gamma \pi
        + \sum_{i \in [n]} \rho_i \\
      \text{s.t.}\quad
      & \pi + \rho_i \ge d_i x_i && \forall i \in [n], \\
      & x \in \mathcal{X}, \\
      & \pi \ge 0,\quad \rho_i \ge 0 && \forall i \in [n].
      \end{empheq}
      \end{mdframed}

      This formulation preserves the combinatorial structure of the shortest-path
      problem while incorporating controlled worst-case protection against uncertain
      edge costs.

      Bertsimas and Sim show that the inner maximization problem admits a compact dual
      reformulation that introduces one global variable and one auxiliary variable per
      uncertain coefficient. The resulting robust counterpart scales linearly in the number
      of edges and constraints. For shortest-path problems, this reformulation preserves
      polynomial solvability at the continuous level: whenever the nominal problem is
      solvable in polynomial time, the corresponding budgeted robust counterpart remains
      polynomially solvable as a linear optimization problem \cite{bertsimas2004,bertsimas2003}.

      Importantly, this complexity guarantee applies to the continuous robust counterpart.
      Integrality enforcement and solver settings are discussed in
      Section~\ref{sec:solver-settings}.

      \paragraph{Summary}
      Table~\ref{tab:computational-comparison} summarizes the main computational properties
      of the two uncertainty models.


      \begin{table}[htbp]
      \centering
      \small
      \renewcommand{\arraystretch}{1.15}
      \begin{tabular}{p{4.2cm} p{4.8cm} p{4.8cm}}
      \toprule
      \textbf{Aspect}
      & \textbf{Discrete Uncertainty}
      & \textbf{Budgeted Uncertainty} \\
      \midrule
      Uncertainty representation
      & Explicit finite scenarios
      & Nominal values with bounded deviations \\

      Robust constraints
      & One per scenario
      & One per edge \\

      Extra variables
      & One epigraph variable ($z$)
      & One global variable ($\pi$) and $|E|$ auxiliary variables ($\rho_e$) \\

      Model size scaling
      & $O(|E| + |V| + |\Omega|)$
      & $O(|E| + |V|)$ \\

      Theoretical complexity
      & NP--hard in general \cite{yu1998,aissi2009}
      & Polynomial (continuous relaxation) \cite{bertsimas2004} \\

      Worst-case modeling
      & Exact over scenarios
      & Aggregated worst-case envelope \\
      \bottomrule
      \end{tabular}
      \caption{Comparison of computational properties of discrete scenario-based and budgeted
      uncertainty min--max shortest-path models.}
      \label{tab:computational-comparison}
      \end{table}


      This section established the theoretical foundation for ex-ante shortest-path
      planning under uncertainty.
      Robust combinatorial optimization models uncertainty explicitly at planning time
      and yields solutions with worst-case performance guarantees.
      While discrete uncertainty enumerates extreme realizations explicitly, budgeted
      uncertainty replaces enumeration by a continuous envelope that bounds coordinated
      deviations across edges.
      In the following section, this approach is contrasted with search-based
      path-planning algorithms that address uncertainty ex post through adaptive
      replanning during execution.



\section{Incremental Search-Based Path-Planning}
\label{sec:incremental-search-based-path-planning}
  We introduced heuristic search methods for the nominal shortest-path problem
  in Section~\ref{sec:shortest-path-planning-under-uncertainty}, where traversal
  costs are assumed to be static and fully known.
  Incremental search methods can be understood as extensions of heuristic
  search—most notably A*—to settings in which costs may change during execution.
  We refer mainly to \cite{koenig2002} for this sections details about D* Lite.

  While A* recomputes a shortest path from scratch when edge costs change,
  incremental search-based methods instead repair their internal search state.
  Rather than discarding previous results, they exploit the optimal substructure
  of shortest paths to reuse prior search effort \cite{koenig2004,stentz1994}.
  These methods maintain lower-bound estimates on the remaining cost-to-go and
  update only those parts of the search space that are affected by newly revealed
  information.
  In this sense, incremental search constitutes a minimal relaxation of the
  nominal heuristic search framework: the underlying graph structure remains
  unchanged, Bellman-style optimality is preserved locally, and global optimality
  is recovered incrementally as traversal costs evolve during execution.

    \paragraph{Conceptual View: Backward Search and Forward Execution}
    D*~Lite maintains a backward shortest-path tree rooted at the goal and incrementally
    updates this structure as traversal costs change.
    All search operations are performed backward from the goal, whereas execution
    proceeds forward from the agent’s current position.
    Consequently, the agent does not plan forward directly but selects actions by
    querying the maintained backward cost-to-go information (see Figure~\ref{fig:dstar-internals} for visualization).

    \paragraph{State Representation and Local Consistency}
    Let $G=(S,E)$ be a directed graph with nonnegative edge costs.
    We consider a fixed goal vertex $s_{\text{goal}}$ and an initial start vertex
    $s_{\text{init}}$.
    The vertex $s_{\text{start}}$ denotes the current position of the mobile agent
    and changes as the agent moves during execution.
    For each vertex $s \in S$, D*~Lite maintains a cost-to-go estimate $g(s)$ and a
    one-step lookahead value
    \[
    \mathrm{rhs}(s) =
    \begin{cases}
    0, & \text{if } s = s_{\text{goal}}, \\
    \min_{s' \in \mathrm{Succ}(s)} \bigl(c(s,s') + g(s')\bigr), & \text{otherwise}.
    \end{cases}
    \]
    The value $g(s)$ represents the currently stored estimate of the shortest-path
    cost from $s$ to $s_{\text{goal}}$.
    It can be interpreted as a previously committed $\mathrm{rhs}(s)$ value and may
    therefore become outdated when edge costs change or when the start vertex
    moves.

    A vertex is said to be \emph{locally consistent} if $g(s)=\mathrm{rhs}(s)$.
    Inconsistencies indicate that the stored cost-to-go information at $s$ no longer
    reflects the current environment.
    D*~Lite restores optimality by incrementally re-establishing local consistency
    only for affected vertices.

    \paragraph{Priority Queue and Lexicographic Keys}
    All locally inconsistent vertices are stored in a priority queue $U$.
    The next vertex to expand ($u$) is the one with the smallest lexicographic key.
    Each vertex in $U$ is assigned a key
    \[
    k(s)=
    \begin{bmatrix}
      k_1 \\
      k_2
    \end{bmatrix}
    =
    \begin{bmatrix}
    \min\{g(s),\mathrm{rhs}(s)\} + h(s_{\text{start}},s) + k_m \\
    \min\{g(s),\mathrm{rhs}(s)\}
    \end{bmatrix},
    \]
    where the second component acts as a tie-breaker and the first component orders
    vertices by the best current estimate of total cost-to-go.
    The use of $\min\{g(s),\mathrm{rhs}(s)\}$ ensures that both over- and
    under-consistent vertices are prioritized by their most reliable estimate,
    generalizing the $f$- and $g$-value ordering of A*.

    \paragraph{Heuristic Shift under Start-Vertex Movement}
    When the agent moves, the start vertex changes and the heuristic term appearing in
    each priority key changes accordingly, which would normally require reordering the
    entire priority queue.
    D*~Lite avoids this overhead by introducing a heuristic shift variable $k_m$, which
    accumulates the heuristic change between successive start positions and preserves
    the relative ordering of keys in the queue.
    This mechanism enables efficient incremental replanning without recomputing
    priorities from scratch.
    Koenig and Likhachev~\cite{koenig2002} also present a variant of D*~Lite that operates
    without this heuristic shift; in this thesis, we focus on the optimized formulation
    that incorporates $k_m$.

    Admissibility requires the heuristic to never overestimate true shortest-path costs.
    Consistency strengthens this condition by additionally enforcing a triangle
    inequality with respect to true shortest-path costs,
    \[
      h(s,s'') \le c^*(s,s') + h(s',s'') \quad \forall s,s',s'' \in V,
    \]
    which ensures monotonic behavior along optimal paths.
    In D*~Lite, consistency is crucial because heuristic values are reused across
    incremental repairs and start-vertex shifts; without it, the correctness of the
    priority queue ordering could not be guaranteed.


      \paragraph{Computational Effort}
    Incremental search methods trade full re-planning for localized updates. In the
    worst case, when cost changes are widespread, D*~Lite may revisit a large portion
    of the graph and its work approaches that of a full A* search for the current
    start--goal pair. When changes are sparse, only a small set of vertices becomes
    locally inconsistent, so updates are confined to affected regions and prior search
    effort is reused. As a result, computational effort depends on graph size, heuristic
    quality, and the magnitude and frequency of cost updates.

    \paragraph{Algorithmic Overview}
    Figure~\ref{fig:dstar-internals} summarizes the algorithmic flow: backward
    propagation from $s_{\text{goal}}$ maintains a consistent search tree,
    the agent executes forward from $s_{\text{start}}$, and any newly revealed costs
    trigger local inconsistency and subsequent repair through renewed backward
    propagation.
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=\textwidth]{figs/DStar_internal.png}
      \caption{Visualization of D* Lite internals, illustrating backward search,
      heuristic guidance, and forward path execution.}
      \label{fig:dstar-internals}
    \end{figure}
    \clearpage
    \paragraph{Procedural Realization}
    We now describe how the above invariants are enforced algorithmically in D*~Lite,
    following the original pseudocode by Koenig and Likhachev~\cite{koenig2002}:


\vspace{0.8cm}

\noindent
\begin{minipage}[t]{0.47\textwidth}
\textbf{Priority Key Computation}

\textit{CalculateKey} ties the invariant definitions to the queue ordering by
combining $\min\{g(s),\mathrm{rhs}(s)\}$ with the heuristic estimate and the
shift variable $k_m$.
The heuristic appears only in this step, ensuring admissible guidance without
violating correctness.
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}
\vspace{1cm}
\centering
\includegraphics[width=\linewidth]{figs/CalculateKeys.png}
\captionof{figure}{Priority key computation in \textit{CalculateKey} \cite{koenig2002}.}
\label{fig:dstarlite-calculatekey}
\end{minipage}



\vspace{0.8cm}
\noindent
\begin{minipage}[t]{0.47\textwidth}
\textbf{Initialization}
All $g$- and $\mathrm{rhs}$-values are initialized to infinity.
The goal vertex is assigned $\mathrm{rhs}(s_{\text{goal}})=0$ and inserted as the
only element in the priority queue.
This initialization seeds the backward search from the goal and establishes the
initial locally consistent state from which cost-to-go information is propagated.
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}
\vspace{0.2cm} % ← adjust freely
\centering
\includegraphics[width=\linewidth]{figs/Initialize.png}
\captionof{figure}{D* Lite initialization procedure \cite{koenig2002}.}
\label{fig:dstarlite-initialize}
\end{minipage}


\vspace{0.8cm}

\noindent
\begin{minipage}[t]{0.47\textwidth}
\textbf{Local Consistency Maintenance}

\textit{UpdateVertex} recomputes the one-step lookahead value $\mathrm{rhs}(s)$ and
updates the membership of $s$ in the priority queue $U$.
Vertices that are locally inconsistent are inserted into or updated within $U$,
while locally consistent vertices are removed.
This procedure constitutes the fundamental mechanism by which D*~Lite restores
local consistency after changes in edge costs or state values.
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}
\vspace{1.7cm}
\centering
\includegraphics[width=\linewidth]{figs/UpdateVertex.png}
\captionof{figure}{Local consistency maintenance via \textit{UpdateVertex} \cite{koenig2002}.}
\label{fig:dstarlite-updatevertex}
\end{minipage}


\vspace{0.8cm}

\noindent
\begin{minipage}[t]{0.47\textwidth}
\textbf{Backward Search and Consistency Repair}

\textit{ComputeShortestPath} repeatedly expands the smallest key in $U$ until the
current start vertex is locally consistent and no better key remains.
Because changes propagate through predecessor relationships, the repair step is
a backward search from $s_{\text{goal}}$.
This procedure is re-entered whenever cost changes introduce new inconsistencies.
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}
\vspace{-0.1cm}
\centering
\includegraphics[width=\linewidth]{figs/ComputeShortestPath.png}
\captionof{figure}{Backward consistency repair in \textit{ComputeShortestPath} \cite{koenig2002}.}
\label{fig:dstarlite-computeshortestpath}
\end{minipage}






\vspace{0.8cm}

\noindent
\begin{minipage}[t]{0.47\textwidth}
\textbf{Interleaving Planning and Execution}

The main loop alternates between greedy forward execution and incremental repair.
At each step, the agent selects the successor that minimizes $c(s,s')+g(s')$,
detects changes in traversal costs, updates affected vertices, and invokes
\textit{ComputeShortestPath} as needed to re-establish local consistency.
This interleaving of execution and replanning constitutes the core mechanism of
D*~Lite and provides a natural integration point for the hybrid extensions
considered in this thesis.
\end{minipage}
\hfill
\begin{minipage}[t]{0.47\textwidth}
\vspace{+0.50cm}
\centering
\includegraphics[width=\linewidth]{figs/Main.png}
\captionof{figure}{Interleaved planning and execution in \textit{Main} \cite{koenig2002}.}
\label{fig:dstarlite-main}
\end{minipage}






\chapter{IMPLEMENTATION DETAILS}
      We discuss our experimental framework implementation in this chapter.
      For details about the programming environment see Chapter 6.

    \section{Decision Support Interface}
      The experimental pipeline is implemented as a lightweight, model- and data-driven decision support system (DSS) 
      that orchestrates data generation, model execution, and result visualization. 
      It provides a unified control interface for executing all experiments under identical parameter settings 
      and for producing directly comparable outputs (Figure~\ref{fig:topdown-architecture-DSS}). 
      The DSS is implemented as a \texttt{Streamlit} application, which eliminates the need for a dedicated backend 
      framework and facilitates rapid prototyping. While the system is primarily intended to be run locally, a deployed 
      instance is also provided to demonstrate portability, albeit with restricted access due to licensing restrictions.


    \section{Data and Graph Generation}
    \label{sec:geostatistical_formulation}
      This section links the implementation in the STGRF generator to the
      formulations in the appendix (Chapter~\ref{chap:appendix}). Each step below states the code
      action and its mathematical counterpart.
      We use the \texttt{GSTools} and \texttt{NetworkX} libraries.

      \paragraph{Step 1: Covariance model and kernel selection}
        A kernel from \texttt{GSTools} (e.g., Gaussian, Mat\'ern, Stable) (see Table~\ref{tab:gstools-covariance-models}) is selected and
        parameterized by variance $\sigma^2$, length scale $\ell$, anisotropy ratios $a_i$,
        and (if applicable) kernel-specific parameters $\nu$ or $\alpha$.
        In the implementation this corresponds to

        \noindent
        \texttt{Kernel(spatial\_dim=3, temporal=False, var=\dots, len\_scale=\dots, anis=\dots)}.

        This instantiates the covariance model $C(r)$ in \eqref{eq:covariance} with
        $\operatorname{cor}(\cdot)$ from \eqref{eq:correlation}.
        The anisotropy ratios define effective correlation lengths
        $\ell_i = \ell a_i$ and enter the metric distance in
        \eqref{eq:metric_xyz}, which in turn defines the spatio-temporal covariance in
        \eqref{eq:metric_spatiotemporal}. Time is treated as a third spatial dimension
        (spatial dimension $d=3$), consistent with
        $\mathbf{x}=(x,y,\tau)$.

    \paragraph{Step 2: Structured space--time grid.}
    The implementation constructs the coordinate arrays
    \[
    x = (0,\Delta,\dots,(N-1)\Delta), \quad
    y = (0,\Delta,\dots,(N-1)\Delta), \quad
    \tau = (0,\dots,|\mathcal{T}|-1),
    \]
    where $\Delta$ is the cell size and $N$ is the number of grid points per axis
    (\texttt{grid\_size} in the implementation). These arrays define the structured grid
    on which the field is evaluated, and each grid point corresponds to a coordinate
    vector $\mathbf{x}=(x,y,\tau)$ in the formulation of $Z(\mathbf{x})$.
    Let
    \[
    Z(\mathbf{x}), \quad \mathbf{x} \in \mathbb{R}^d,
    \]
    denote a real-valued random field indexed over a $d$-dimensional domain.

    \paragraph{Step 3: Spectral random field generation.}
    Given the covariance model, \texttt{GSTools} constructs a stationary Gaussian random
    field via its spectral randomization method.
    The call \texttt{SRF(model, seed).structured([x, y, t])}, where \texttt{t} is the
    scenario index array $\tau$, produces samples $Z(\mathbf{x})$ on the structured
    grid, implementing the generation in
    \eqref{eq:srf_generation} for the covariance in \eqref{eq:metric_spatiotemporal}.

    \paragraph{Step 4: Global normalization.}
      To ensure nonnegative and comparable costs across scenarios, the sampled three-dimensional field is 
      rescaled according to
    \[
    \tilde{Z} = \frac{Z - \min Z}{\max Z - \min Z},
    \]
    where the minimum and maximum are taken over the entire space–time grid. 
    This transformation maps all costs to the unit interval [0,1]. 
    The implications of this normalization for experimental results are discussed in Chapter~\ref{chap:experiments}.
    

    \paragraph{Step 5: Scenario slices and graph mapping.}
    For each scenario index $\tau$, the 2D slice
    $f_{\tau}(x,y) := Z(x,y,\tau)$ is extracted as the spatial cost surface.
    The routing graph is generated as a directed 4-connected grid using \texttt{NetworkX}; each grid point $(x,y)$ is mapped
    to a node id $i = xN + y$. Each directed edge $(i,j)$ receives the mean of its
    incident node values,
    \[
    c(i,j) = \tfrac{1}{2}\bigl(f_{\tau}(x_i,y_i) + f_{\tau}(x_j,y_j)\bigr),
    \]
    yielding a scenario-specific edge-cost graph derived directly from the realization
    $Z(\mathbf{x})$.

    \paragraph{Step 6: Export for downstream models.}
    The implementation writes a global node file and one edge file per scenario, as well
    as the per-scenario field slices, enabling downstream shortest-path and robust
    optimization models to consume the same spatio-temporal realizations.

    \section{Discrete Uncertainty Min--Max Model}
      This section instantiates the discrete scenario-based min--max formulation introduced in
      Section~\ref{sec:robust-combinatorial-optimization}.

      The directed graph $G=(V,E)$ is constructed from \texttt{nodes.csv} and \newline
      \texttt{scenario\_000/edges.csv}, which fixes a consistent edge index set shared across all
      scenarios (Section~\ref{sec:data-component}).

      For each scenario $\omega \in \Omega$, the corresponding edge-cost vector
      $\mathbf{c}^{\omega}$ is read from \texttt{scenario\_$\omega$/edges.csv} and aligned to this
      common indexing.

      The mixed-integer linear program is formulated using binary edge-selection variables $x_e$
      and a continuous epigraph variable $z$.
      Path feasibility is enforced via the flow-balance constraints
      (\ref{eq:flow-balance-constraint}), while robustness with respect to discrete uncertainty
      is captured through the scenario-wise constraints
      $z \ge \sum_{e\in E} c_e^{\omega} x_e$ for all $\omega \in \Omega$.
      No additional modeling assumptions are introduced at the implementation level.
      The resulting MILP is solved using Gurobi with the solver configuration described in
      Section~\ref{sec:solver-settings}.

      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Discrete-Scenario Min--Max Shortest-Path Model}
      \begin{empheq}{align}
      \min_{x,\,z}\quad
      & z \\[0.3em]
      \text{s.t.}\quad
      & z \;\ge\; \sum_{e\in E} c_e^{\omega}\,x_e
      && \forall \omega\in\Omega, \\[0.3em]
      & \sum_{e \in \delta^+(v)} x_e \;-\; \sum_{e \in \delta^-(v)} x_e \;=\;
      \begin{cases}
        1, & v = s, \\
      -1, & v = t, \\
        0, & \text{otherwise,}
      \end{cases}
      && \forall v\in V, \\[0.3em]
      & x_e \in \{0,1\}
      && \forall e\in E, \\[0.3em]
      & z \in \mathbb{R}.
      \end{empheq}
      \end{mdframed}

      The solution represents an $s$--$t$ path that is feasible across all scenarios and minimizes
      the worst-case realized traversal cost.
      Theoretical complexity and model-size properties of the discrete min--max formulation are
      discussed in Section~\ref{subsec:computational-efficiency-robust-models}.


    \newpage
  
    \section{Budgeted Uncertainty Min--Max Model}
      This section instantiates the budgeted uncertainty formulation introduced in
      Section~\ref{sec:robust-combinatorial-optimization}.
      In contrast to the discrete scenario-based model, scenario-dependent edge costs
      are first aggregated in a preprocessing step to obtain a nominal cost and an
      associated maximum deviation for each edge.
      Let $\Omega$ denote the set of cost scenarios and let $c_e^{\omega}$ be the cost
      of edge $e$ under scenario $\omega \in \Omega$.

      Scenario costs are aggregated using
      (\ref{eq:nominal-avg})--(\ref{eq:deviation}), while preserving the same edge
      indexing as in the discrete uncertainty model.
      The resulting nominal costs $\underline{c}_e$ and deviations $d_e$ are treated
      as fixed parameters in the robust optimization model.
      The robust counterpart is formulated using binary edge-selection variables $x_e$,
      a global deviation variable $\pi$, and auxiliary variables $\rho_e$.
      Path feasibility is enforced via the flow-balance constraints
      (\ref{eq:flow-balance-constraint}), while robustness is captured by the
      budgeted constraints $\pi + \rho_e \ge d_e x_e$ for all $e \in E$.
      The uncertainty budget $\Gamma$ is treated as an experimental parameter, and
      solver limits and integrality settings follow
      Section~\ref{sec:solver-settings}.

      The nominal cost $\underline{c}_e$ is defined either as the minimum observed cost
      (\ref{eq:nominal-min}) or as the average cost across all scenarios
      (\ref{eq:nominal-avg}).
      The deviation $d_e$ captures the maximum adverse deviation from the nominal value
      and is computed as (\ref{eq:deviation}).
      \begin{align}
      \underline{c}_e^{\min} 
      &= \min_{\omega \in \Omega} c_e^{\omega}, 
      \label{eq:nominal-min}
      \\[0.5em]
      \underline{c}_e^{\text{avg}} 
      &= \frac{1}{|\Omega|} \sum_{\omega \in \Omega} c_e^{\omega},
      \label{eq:nominal-avg}
      \\[0.5em]
      d_e 
      &= \max_{\omega \in \Omega} c_e^{\omega} - \underline{c}_e.
      \label{eq:deviation}
      \end{align}

      These quantities define a budgeted uncertainty representation in which the
      realized cost of each edge may increase from its nominal value by at most $d_e$,
      subject to a global uncertainty budget.
      In preliminary experiments, using the minimum-based nominal cost
      (\ref{eq:nominal-min}) resulted in an overly optimistic abstraction of the
      underlying cost field when compared to the remaining planning paradigms.
      Therefore, all subsequent experiments employ the average-based nominal cost
      (\ref{eq:nominal-avg}) in combination with the deviation definition in
      (\ref{eq:deviation}).


      \vspace{0.4cm}
      \begin{mdframed}[
        linewidth=0.8pt,
        roundcorner=5pt,
        innerleftmargin=10pt,
        innerrightmargin=10pt,
        innertopmargin=10pt,
        innerbottommargin=10pt
      ]
      \textbf{Budgeted-Uncertainty Min--Max Robust Shortest-Path}
      \begin{empheq}{align}
      \min_{x,\,\pi,\,\rho}\quad
      & \sum_{e\in E} \underline{c}_e\,x_e
        \;+\; \Gamma\,\pi
        \;+\; \sum_{e\in E} \rho_e 
        \label{eq:budgeted-robust-objective-function}
        \\[0.3em]
      \text{s.t.}\quad
      & \pi + \rho_e \;\ge\; d_e\,x_e
      && \forall e\in E, \\[0.3em]
      & \sum_{e \in \delta^+(v)} x_e \;-\;
        \sum_{e \in \delta^-(v)} x_e \;=\;
      \begin{cases}
        1, & v = s, \\
      -1, & v = t, \\
        0, & \text{otherwise,}
      \end{cases}
      && \forall v\in V, \\[0.3em]
      & x_e \in \{0,1\}
      && \forall e\in E, \\[0.3em]
      & \pi \ge 0,\;\rho_e \ge 0
      && \forall e\in E.
      \label{eq:budgeted-robust-last}
      \end{empheq}
      \end{mdframed}

      This formulation yields an $s$--$t$ path that is robust with respect to the
      budgeted uncertainty set.
      Theoretical complexity results are summarized in
      Section~\ref{subsec:computational-efficiency-robust-models}, while solver
      settings and integrality enforcement are described in
      Section~\ref{sec:solver-settings}.

    \section{Solver Settings}
    \label{sec:solver-settings}
    Both robust models are implemented as mixed-integer linear programs and solved using
    the \texttt{Gurobi} optimizer via its Python interface. Unless stated otherwise, all
    runs use a wall-clock time limit of 60 seconds and a relative MIP optimality gap of
    2\%, with presolve routines, cutting planes, and branching strategies left at solver
    defaults. Binary edge-selection variables enforce path integrality; the budgeted
    deviation constraints do not preserve total unimodularity in general, so the linear
    relaxation can be fractional. Gurobi solves the MILPs via branch-and-bound; reported
    runtimes correspond to solver wall-clock time measured on identical hardware.

    \newpage
    
\section{D* Lite}
\label{app:dstar_lite}
We implement D*~Lite in accordance with the reference pseudocode as described in
Chapter~\ref{chap:conceptual-foundations},
Section~\ref{sec:incremental-search-based-path-planning}.
All theoretical properties and correctness guarantees of D*~Lite are discussed in
Chapter~2.

\paragraph{Modeling Differences.}
Compared to the reference formulation by Koenig and
Likhachev \cite{koenig2002}, the following modeling and implementation choices are
adopted:
\begin{itemize}
  \item a 4-connected grid graph instead of 8-connectivity; consequently, an
        admissible Manhattan-distance heuristic is used rather than a Euclidean
        heuristic,
  \item initial edge costs are derived from the first STRF realization rather than
        uniform default values,
  \item edges are never blocked; unfavorable regions are modeled exclusively via
        increased traversal costs,
  \item the priority queue is implemented using the \texttt{heapq} library.
        Queue updates rely on lazy deletion, i.e., outdated entries are discarded
        upon extraction rather than removed explicitly.
        This implementation choice preserves the algorithmic behavior and
        correctness of D*~Lite while simplifying queue management.
\end{itemize}
These choices ensure structural consistency with the robust optimization models
and isolate uncertainty effects to edge costs.

\paragraph{Preprocessing and Graph Construction.}
Prior to executing D*~Lite, the graph structure and associated cost data are
constructed from the CSV inputs.
Vertices are loaded from \texttt{nodes.csv} and mapped to planar coordinates
$\texttt{node\_id} \mapsto (x,y)$.
Directed edges and their initial traversal costs are read from
\texttt{scenario\_000/edges.csv}, from which adjacency lists of successors and
predecessors are constructed.
All vertices are included in the graph, including those without outgoing edges.

For each subsequent scenario directory \texttt{scenario\_$\omega$} with
$\omega \ge 1$, the corresponding \texttt{edges.csv} file is parsed and stored as
a complete list of edge--cost triples $(u,v,c)$.
Scenario files are stored as complete edge--cost lists and are processed on
demand during execution as part of the scenario-based cost evolution mechanism.

If a robust offline path is provided, it is loaded as an ordered sequence of node
identifiers and used to construct guidance beacons as described above.
Otherwise, the algorithm proceeds without global guidance.



\paragraph{Scenario-Based Cost Evolution.}
The original D*~Lite algorithm assumes static edge costs, while allowing cost
changes to be revealed during execution.
However, the reference pseudocode by Koenig and Likhachev~\cite{koenig2002}
(lines~\{37--38\} in the \textit{Main()} procedure) does not prescribe a concrete
mechanism for detecting or generating edge-cost updates; such changes are treated
as exogenous events.
This mechanism is referred to as \emph{scenario-based cost evolution} in the
remainder of this section.

To operationalize this assumption under spatio-temporal uncertainty, traversal
costs are modeled as a sequence of time-indexed cost maps derived from
spatio-temporal random field (STRF) realizations.
Each realization defines a complete edge-cost assignment that remains fixed over
a finite execution interval.

The base graph is initialized using the first realization
(\texttt{scenario\_000}).
A deterministic update schedule controls when subsequent cost maps become active.
Let
\[
\texttt{steps\_per\_layer}
=
\left\lceil
\frac{|x_s - x_t| + |y_s - y_t|}{|\Omega|}
\right\rceil,
\]
where $|x_s - x_t| + |y_s - y_t|$ denotes the Manhattan distance between start and
goal, and $|\Omega|$ is the number of available scenarios.
After each forward move, a step counter is incremented; when it reaches
\texttt{steps\_per\_layer}, the active scenario index is advanced (capped at the
final scenario) and the counter is reset.
Because the graph is initialized with \texttt{scenario\_000} while the active
scenario index starts at~1, the updates corresponding to
\texttt{scenario\_001} are applied immediately after the first movement step;
subsequent scenario changes occur every
\texttt{steps\_per\_layer} forward moves.
Thus, the initial backward search is computed on \texttt{scenario\_000}, 
but the first update step switches to \texttt{scenario\_001} immediately after the 
first forward move, so the initial search primarily guides that first action and 
seeds the subsequent incremental replanning.

\paragraph{Coupling Robust Planning and Incremental Execution.}
When a robust offline path is available, it is used exclusively as coarse
guidance for incremental execution.
Let the robust path be given as an ordered sequence of nodes.
Removing the start and goal yields an interior node list of length $n$.
A maximum number of guidance points (beacons) is specified as an experimental
parameter.
We set
\[
c = \min\{\texttt{beacon\_cap},\, n\},
\]
partition the interior list into $c$ contiguous segments, and select the midpoint
node of each segment.
The selected nodes form the beacon sequence, with at most $c$ beacons.

If at least one beacon is present, the first beacon is used as the initial goal;
otherwise, the final destination node is used.
At any time, exactly one beacon is active.
Whenever a new beacon becomes active—either by schedule or upon reaching the
current beacon—the D*~Lite search state is fully reinitialized: all $g$- and
$\mathrm{rhs}$-values are reset, the priority queue is cleared, and the new goal
vertex is inserted before invoking \textit{ComputeShortestPath()}.
This design intentionally discards cross-goal reuse in order to isolate the
effect of global guidance from local replanning.

Beacon activation follows two rules.
First, when the agent reaches the currently active beacon, the next beacon in the
sequence is activated immediately.
Second, beacons may be activated periodically in response to scenario changes.
Let $L = \texttt{max\_scenario} + 1$ denote the total number of scenario layers
and let $B$ be the number of beacons.
The activation interval is defined as $\lceil L / B \rceil$, and a beacon is
activated when
\[
(\texttt{current\_scenario} - 1) \bmod \lceil L / B \rceil = 0,
\]
with at most one activation per scenario layer.
Once all beacons have been exhausted, the final goal is restored and the
algorithm proceeds without further global guidance.




\chapter{EXPERIMENTAl RESULTS}
    In our experiments, global path planners are evaluated with respect to solution quality
    and computational effort. 

    For each configuration, results are aggregated over runs using identical seeds across algorithms.
    We report the median realized costs and median runtime. 
    Uncertainty is summarized via a non-paramteric bootstrap 95\% confidence interval of the median cost.
    Our CI is estimated by repeatedly resampling observed costs with replacement 1,000 times.
    Each resample is the same size as the original sample and we compute the median for each resample.
    We then take the 2.5th and 97.5th percentiles of those 1,000 medians as the 95\% CI.

    This combination provides a statistically sound and interpretable summary of algorithmic
    performance under stochastic spatio-temporal uncertainty.

    Two-layer experiments:
    \begin{itemize}
      \item layer: run extremes to find out which parameters yield the most promising comparison results
      \item layer: re-run promising parameters in greater variability 
    \end{itemize}

      \paragraph{Research Questions}
    To achieve the stated research objective, this thesis addresses the following research
    questions through experimental evaluation:

    \begin{itemize}
      \item[RQ1:] How do ex-ante robust optimization and ex-post adaptive search-based planning
      methods compare in terms of path quality and realized traversal cost under identical
      spatio-temporal cost uncertainty?

      \item[RQ2:] What are the computational trade-offs between robust optimization models and
      incremental search methods when applied to shortest-path planning under uncertainty?

      \item[RQ3:] How does execution-time adaptivity influence the performance of planning
      approaches in environments with dynamically evolving traversal costs?

      \item[RQ4:] Can a hybrid planning approach that combines robust ex-ante guidance with
      incremental ex-post replanning improve performance compared to using either paradigm
      in isolation?
    \end{itemize}

    \paragraph{Computational Effort}
    In line with Section~\ref{subsec:computational-efficiency-robust-models}, runtime is
    analyzed with respect to the scenario count $|\Omega|$ for discrete uncertainty and
    the uncertainty budget $\Gamma$ for budgeted uncertainty. We report median solver
    runtimes alongside cost statistics in the results below.



    \newpage
  \section{Baseline}
        These are the baseline parameters we test our models with and compare to.
        To keep our experiments reasonable and comparable, interesting parameters will be changed with the remaining parameters unchanged.
        \begin{table}[htbp]
        \centering
        \caption{Baseline experimental configuration}
        \label{tab:baseline-config}
        \begin{tabular}{lll}
        \toprule
        \textbf{Parameter} & \textbf{Symbol/ Description} & \textbf{Value} \\
        \midrule
        Grid size & $N_p \times N_q$ & $20 \times 20$ \\
        Anisotropy & $(a_p, a_q, a_t)$ & $(1.0,\;1.0,\;1.0)$ \\
        Number of scenarios & $|\mathcal{T}|$ & $10$ \\
        Spatial scaling factor & $\alpha$ & $0.25$ \\
        Temporal scaling factor & $\beta$ & $0.30$ \\
        Gamma scaling factor & $\lambda$ & $0.10$\\
        Spatial length scales & $(\ell_p,\ell_q)$ & $(\alpha N_p,\; \alpha N_q)$ \\
        Temporal length scale & $\ell_t$ & $\beta |\mathcal{T}|$ \\
        Variance & $\sigma^2$ & $1.0$ \\
        Robustness budget & $\Gamma$ & $\Gamma(\lambda) = \lambda \Gamma_{\max}$ \\
        Covariance model & -- & Gaussian \\
        Seed range & -- & $1$--$100$ \\
        Milestone cap (D* Lite) & -- & $10$ \\
        \bottomrule
        \end{tabular}
        \end{table}


        \begin{table}[htbp]
        \centering
        \label{tab:results-baseline}
        \begin{tabular}{lccc}
        \toprule
        Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
        \midrule
        Discrete Uncertainty
        & 17.19 & [16.55, 17.98] & 287.55 \\

        Budgeted Uncertainty
        & 17.04 & [16.37, 17.35] & 85.43 \\

        D* Lite
        & 18.05 & [17.38, 18.92] & 230.96 \\

        D* Lite w. discrete guidance
        & 16.28 & [15.33, 17.00] & 231.38 \\

        D* Lite w. budgeted guidance
        & 15.33 & [14.57, 16.12] & 231.29 \\
        \bottomrule
        \end{tabular}
        \caption{Performance comparison under the baseline configuration.}
        \end{table}

\begin{figure}[htbp]
\noindent
\begin{minipage}[t]{0.3\textwidth}
    \vspace{0pt} % <-- KEY FIX
    \raggedright
    \includegraphics[width=\linewidth]{figs/Baseline2D.png}
\end{minipage}
\hfill
\begin{minipage}[t]{0.68\textwidth}
    \vspace{0.5cm} % <-- KEY FIX
    \small
    Many real-world planning and routing decisions must be made under conditions
    of uncertainty and dynamic change. Traversal costs may depend on environmental
    factors such as weather conditions, terrain properties, or sensor noise and
    may vary over both space and time.

    This illustration shows how heterogeneous environmental sensor data can be
    spatially aggregated into a continuous cost field that serves as input for
    graph-based routing models.
\end{minipage}
\caption{Visualization of the baseline cost field for the first time frame.}
\end{figure}

    \paragraph{Length Scale}
          To ensure comparability across instance sizes, correlation lengths are defined relative to the extent
      of the modeled domain. Throughout all experiments, the spatial discretization is kept fixed, i.e.,
      the cell size satisfies $\Delta p = \Delta q = 1$, and correlation lengths are therefore expressed
      directly in grid units. Spatial correlation lengths are scaled proportionally with grid size according
      to
      \[
      \ell_p = \alpha N_p, \qquad \ell_q = \alpha N_q,
      \]
      where the scaling constant $\alpha$ is calibrated from a reference configuration. This construction
      keeps the ratio $\ell / N$ constant and thereby preserves the relative spatial smoothness of the
      generated cost fields across grid resolutions.

      Temporal correlation is defined relative to the scenario horizon $|\mathcal{T}|$ (with fixed time step). When
      $|\mathcal{T}|$ is fixed (e.g., $|\mathcal{T}| = 10$), the temporal correlation length $\ell_t$ is kept constant; if $|\mathcal{T}|$
      changes, we set
      \[
      \ell_t = \beta |\mathcal{T}|,
      \]
      with $\beta$ calibrated analogously, so that the ratio $\ell_t / |\mathcal{T}|$ remains constant.

      The scaling constants are calibrated from the baseline configuration, yielding
      $\alpha = \ell_p^0 / N_p^0 = \ell_q^0 / N_q^0 = 0.25$ and
      $\beta = \ell_t^0 / |\mathcal{T}|^0 = 0.3$.


      \paragraph{Uncertainty Budget}
      Since the budget parameter $\Gamma$ is continuous in our implementation, we
      parameterize robustness via a normalized factor $\lambda \in [0,1]$ and set
      \[
      \Gamma(\lambda) = \lambda \Gamma_{\max}, 
      \qquad 
      \Gamma_{\max} := L_{\min} = (N_p-1) + (N_q-1),
      \]
      where $L_{\min}$ is the minimum number of edges on an $s$--$t$ path in the
      $4$-connected grid. Thus, $\lambda=0$ yields the nominal model, while
      $\lambda=1$ corresponds to full conservatism. We use $\lambda=0.1$ as the
      baseline robustness level.




    \newpage
  
  \section{Experiment 1: Urban vs. Regional Scale}

        \begin{table}[htbp]
          \centering
          \label{tab:param-variations}
              \begin{tabular}{lll}
              \toprule
              \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
              \midrule
              Grid Size             & $20 \times 20$    & \{$50 \times 50$, $75 \times 75$, $100 \times 100$\}\\
              \bottomrule
              \end{tabular}
              \caption{Experiment 1: Parameter variations relative to the baseline configuration}
        \end{table}

        By increasing the overall grid size, we also scale our spatial length scale $(l_x, l_y)$
        as well as our uncertainty budget $\Gamma$.

        \begin{table}[htbp]
        \centering
        \caption{Performance comparison across grid sizes}
        \label{tab:large-instances}
        \resizebox{\textwidth}{!}{%
        \begin{tabular}{c l c c c}
        \toprule
        & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
        \midrule

        % ===== 20x20 (baseline) =====
        \multirow{5}{*}{\rotatebox{90}{$20 \times 20^{\ast}$}}
        & Discrete Uncertainty
        & 17.19 & [16.55, 17.98] & 287.55 \\

        & Budgeted Uncertainty
        & 17.04 & [16.37, 17.35] & 85.43 \\

        & D* Lite
        & 18.05 & [17.38, 18.92] & 230.96 \\

        & D* Lite w.\ Discrete guidance
        & 16.28 & [15.33, 17.00] & 231.38 \\

        & D* Lite w.\ Budgeted guidance
        & 15.33 & [14.57, 16.12] & 231.29 \\

        \midrule

        % ===== 50x50 =====
        \multirow{5}{*}{\rotatebox{90}{$50 \times 50$}}
        & Discrete Uncertainty
        & 44.61 & [42.92, 45.97] & 3160.54 \\

        & Budgeted Uncertainty
        & 43.83 & [42.71, 45.00] & 3989.21 \\

        & D* Lite
        & 47.10 & [44.77, 48.91] & 2011.42 \\

        & D* Lite w.\ Discrete guidance
        & 42.21 & [40.16, 44.06] & 1951.31 \\

        & D* Lite w.\ Budgeted guidance
        & 39.45 & [37.56, 41.49] & 1943.66 \\

        \midrule

        % ===== 75x75 =====
        \multirow{5}{*}{\rotatebox{90}{$75 \times 75$}}
        & Discrete Uncertainty
        & 68.07 & [65.09, 69.42] & 10354.67 \\

        & Budgeted Uncertainty
        & 66.27 & [64.08, 67.79] & 41848.94 \\

        & D* Lite
        & 70.81 & [67.90, 74.09] & 5985.83 \\

        & D* Lite w.\ Discrete guidance
        & 63.25 & [60.74, 65.59] & 5873.51 \\

        & D* Lite w.\ Budgeted guidance
        & 59.39 & [56.82, 62.16] & 5862.06 \\

        \midrule

        % ===== 100x100 =====
        \multirow{5}{*}{\rotatebox{90}{$100 \times 100$}}
        & Discrete Uncertainty
        & 90.90 & [87.12, 92.82] & 26568.95 \\

        & Budgeted Uncertainty
        & 88.91 & [85.00, 90.72] & 61120.00 \\

        & D* Lite
        & 94.80 & [90.50, 100.33] & 14442.30 \\

        & D* Lite w.\ Discrete guidance
        & 85.25 & [81.03, 87.82] & 14037.08 \\

        & D* Lite w.\ Budgeted guidance
        & 79.48 & [75.90, 82.99] & 14346.51 \\

        \bottomrule
        \end{tabular}
        }
        \vspace{0.3em}
        \footnotesize
        $\ast$ Baseline configuration.
        \end{table}




  \newpage
  

  \section{Experiment 2: Short vs. Long Exposure}
  In the short–long exposure experiment we vary the number of scenarios $|\mathcal{T}|$ while keeping the temporal length scale $\ell_t$ fixed. 

    \begin{table}[htbp]
      \centering
      \label{tab:param-variations-scenarios}
          \begin{tabular}{lll}
          \toprule
          \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
          \midrule
          Number of Scenarios & 10 & $\{1, 5, 20, 50, 100\}$ \\
          \bottomrule
          \end{tabular}
      \caption{Experiment 2: Parameter variations relative to the baseline configuration}
    \end{table}

    \begin{table}[htbp]
    \centering
    \caption{Performance comparison across exposure levels $|\mathcal{T}|$}
    \label{tab:number-of-scenarios}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c}
    \toprule
    & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
    \midrule

    % ===== |T| = 1 =====
    \multirow{5}{*}{\rotatebox{90}{$|\mathcal{T}| = 1$}}
    & Discrete Uncertainty
    & 12.35 & [11.58, 13.07] & 80.74 \\

    & Budgeted Uncertainty
    & 12.35 & [11.58, 13.11] & 39.52 \\

    & D* Lite
    & 13.59 & [12.64, 14.80] & 40.46 \\

    & D* Lite w.\ Discrete guidance
    & 12.35 & [11.52, 13.11] & 40.67 \\

    & D* Lite w.\ Budgeted guidance
    & 12.35 & [11.54, 13.10] & 40.64 \\

    \midrule

    % ===== |T| = 5 =====
    \multirow{5}{*}{\rotatebox{90}{$|\mathcal{T}| = 5$}}
    & Discrete Uncertainty
    & 15.18 & [14.11, 15.97] & 167.74 \\

    & Budgeted Uncertainty
    & 14.70 & [14.17, 15.37] & 74.12 \\

    & D* Lite
    & 15.94 & [15.17, 17.22] & 123.71 \\

    & D* Lite w.\ Discrete guidance
    & 14.56 & [13.75, 15.10] & 123.69 \\

    & D* Lite w.\ Budgeted guidance
    & 13.78 & [12.71, 14.35] & 123.77 \\

    \midrule

    % ===== |T| = 10 (baseline) =====
    \multirow{5}{*}{\rotatebox{90}{$|\mathcal{T}| = 10^{\ast}$}}
    & Discrete Uncertainty
    & 17.19 & [16.55, 17.98] & 287.55 \\

    & Budgeted Uncertainty
    & 17.04 & [16.37, 17.35] & 85.43 \\

    & D* Lite
    & 18.05 & [17.38, 18.92] & 230.96 \\

    & D* Lite w.\ Discrete guidance
    & 16.28 & [15.33, 17.00] & 231.38 \\

    & D* Lite w.\ Budgeted guidance
    & 15.33 & [14.57, 16.12] & 231.29 \\

    \midrule


    % ===== |T| = 50 =====
    \multirow{5}{*}{\rotatebox{90}{$|\mathcal{T}| = 50$}}
    & Discrete Uncertainty
    & 18.94 & [18.57, 19.91] & 1406.50 \\

    & Budgeted Uncertainty
    & 19.12 & [18.82, 19.58] & 167.20 \\

    & D* Lite
    & 18.99 & [18.14, 19.57] & 1064.51 \\

    & D* Lite w.\ Discrete guidance
    & 17.64 & [17.36, 17.95] & 1066.09 \\

    & D* Lite w.\ Budgeted guidance
    & 17.40 & [16.90, 18.06] & 1065.92 \\

    \midrule

    % ===== |T| = 100 =====
    \multirow{5}{*}{\rotatebox{90}{$|\mathcal{T}| = 100$}}
    & Discrete Uncertainty
    & 18.84 & [18.17, 19.59] & 2839.01 \\

    & Budgeted Uncertainty
    & 19.80 & [19.53, 20.18] & 278.15 \\

    & D* Lite
    & 19.28 & [18.58, 19.93] & 2011.47 \\

    & D* Lite w.\ Discrete guidance
    & 19.00 & [17.90, 19.56] & 1997.88 \\

    & D* Lite w.\ Budgeted guidance
    & 18.53 & [17.49, 18.97] & 2000.87 \\

    \bottomrule
    \end{tabular}
    }
    \vspace{0.3em}
    \footnotesize
    $\ast$ Baseline configuration.
    \end{table}


Although the budgeted uncertainty model admits a polynomial-size reformulation, its LP relaxation is significantly weaker than that of the discrete min–max formulation. The global uncertainty budget introduces coupling across all edges, allowing the relaxation to distribute deviations fractionally over many arcs. As a result, the solver faces substantially more fractional variables at the root node, leading to slower convergence in practice. In contrast, the discrete uncertainty model yields tighter relaxations despite its theoretical NP-hardness, explaining its superior empirical runtime.






        
    
\newpage


  \section{Experiment 3: Rough vs. Smooth Terrain}
    By varying the spatial scaling factor $\alpha$, we change the spatial length scales and thus the terrain roughness.

    \begin{table}[htbp]
      \centering
      \label{tab:param-variations-var}
          \begin{tabular}{lll}
          \toprule
          \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
          \midrule
          Spatial scaling factor $\alpha$ & 0.25 & $\{0.10, 0.50\}$ \\
          \bottomrule
          \end{tabular}
      \caption{Experiment 4: Parameter variations relative to the baseline configuration}
    \end{table}

    \begin{table}[htbp]
    \centering
    \caption{Performance comparison across spatial scaling factors $\alpha$}
    \label{tab:covariance-kernels}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c}
    \toprule
    & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
    \midrule

    % ===== alpha = 0.10 =====
    \multirow{5}{*}{\rotatebox{90}{$\alpha = 0.10$}}
    & Discrete Uncertainty
    & 16.47 & [16.03, 16.90] & 281.89 \\

    & Budgeted Uncertainty
    & 16.52 & [16.15, 17.00] & 77.05 \\

    & D* Lite
    & 18.46 & [18.11, 19.10] & 231.20 \\

    & D* Lite w.\ Discrete guidance
    & 15.49 & [15.18, 16.03] & 230.87 \\

    & D* Lite w.\ Budgeted guidance
    & 15.28 & [14.80, 16.00] & 230.76 \\

    \midrule

    % ===== alpha = 0.25 (baseline) =====
    \multirow{5}{*}{\rotatebox{90}{$\alpha = 0.25^{\ast}$}}
    & Discrete Uncertainty
    & 17.19 & [16.55, 17.98] & 287.55 \\

    & Budgeted Uncertainty
    & 17.04 & [16.37, 17.35] & 85.43 \\

    & D* Lite
    & 18.05 & [17.38, 18.92] & 230.96 \\

    & D* Lite w.\ Discrete guidance
    & 16.28 & [15.33, 17.00] & 231.38 \\

    & D* Lite w.\ Budgeted guidance
    & 15.33 & [14.57, 16.12] & 231.29 \\

    \midrule

    % ===== alpha = 0.50 =====
    \multirow{5}{*}{\rotatebox{90}{$\alpha = 0.50$}}
    & Discrete Uncertainty
    & 16.91 & [15.75, 18.56] & 271.63 \\

    & Budgeted Uncertainty
    & 17.45 & [16.90, 18.31] & 83.14 \\

    & D* Lite
    & 18.46 & [16.22, 19.84] & 228.03 \\

    & D* Lite w.\ Discrete guidance
    & 16.75 & [14.83, 17.98] & 227.85 \\

    & D* Lite w.\ Budgeted guidance
    & 14.97 & [14.36, 16.68] & 228.19 \\

    \bottomrule
    \end{tabular}
    }
    \vspace{0.3em}
    \footnotesize
    $\ast$ Baseline configuration.
    \end{table}








\newpage


  \section{Experiment 4: Temporal Stability}
    By varying the temporal scaling factor $\beta$, we change the temporal length scale and thus the stability across scenarios.

    \begin{table}[htbp]
      \centering
      \label{tab:param-variations-var}
          \begin{tabular}{lll}
          \toprule
          \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
          \midrule
          Temporal scaling factor $\beta$ & 0.30 & $\{0.10, 0.60\}$ \\
          \bottomrule
          \end{tabular}
      \caption{Experiment 6: Parameter variations relative to the baseline configuration}
    \end{table}

    \begin{table}[htbp]
    \centering
    \caption{Performance comparison across temporal scaling factors $\beta$}
    \label{tab:covariance-kernels}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c}
    \toprule
    & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
    \midrule

    % ===== beta = 0.10 =====
    \multirow{5}{*}{\rotatebox{90}{$\beta = 0.10$}}
    & Discrete Uncertainty
    & 18.69 & [17.80, 19.55] & 324.63 \\

    & Budgeted Uncertainty
    & 18.47 & [18.11, 19.00] & 105.77 \\

    & D* Lite
    & 18.97 & [18.26, 19.93] & 237.79 \\

    & D* Lite w.\ Discrete guidance
    & 17.45 & [16.53, 18.08] & 237.79 \\

    & D* Lite w.\ Budgeted guidance
    & 16.35 & [15.82, 16.99] & 237.63 \\

    \midrule

    % ===== beta = 0.30 (baseline) =====
    \multirow{5}{*}{\rotatebox{90}{$\beta = 0.30^{\ast}$}}
    & Discrete Uncertainty
    & 17.19 & [16.55, 17.98] & 287.55 \\

    & Budgeted Uncertainty
    & 17.04 & [16.37, 17.35] & 85.43 \\

    & D* Lite
    & 18.05 & [17.38, 18.92] & 230.96 \\

    & D* Lite w.\ Discrete guidance
    & 16.28 & [15.33, 17.00] & 231.38 \\

    & D* Lite w.\ Budgeted guidance
    & 15.33 & [14.57, 16.12] & 231.29 \\

    \midrule

    % ===== beta = 0.60 =====
    \multirow{5}{*}{\rotatebox{90}{$\beta = 0.60$}}
    & Discrete Uncertainty
    & 15.32 & [14.53, 16.13] & 284.08 \\

    & Budgeted Uncertainty
    & 14.89 & [14.42, 15.33] & 88.66 \\

    & D* Lite
    & 16.09 & [15.41, 17.25] & 235.29 \\

    & D* Lite w.\ Discrete guidance
    & 14.72 & [13.83, 15.22] & 235.18 \\

    & D* Lite w.\ Budgeted guidance
    & 13.85 & [12.98, 14.50] & 234.96 \\

    \bottomrule
    \end{tabular}
    }
    \vspace{0.3em}
    \footnotesize
    $\ast$ Baseline configuration.
    \end{table}








\newpage


  \section{Experiment 5: Uncertainty Budgeted}
    By varying the robustness budget scaling factor $\lambda$, we change the uncertainty budget $\Gamma=\lambda\Gamma_{\max}$.

    \begin{table}[htbp]
      \centering
      \label{tab:param-variations-var}
          \begin{tabular}{lll}
          \toprule
          \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
          \midrule
          Gamma scaling factor $\lambda$ & 0.10 & $\{0, 0.25, 0.50, 1.00\}$ \\
          \bottomrule
          \end{tabular}
      \caption{Experiment 7: Parameter variations relative to the baseline configuration}
    \end{table}

\begin{table}[htbp]
\centering
\caption{Performance comparison across budget levels $\lambda$}
\label{tab:performance-lambda}
\resizebox{\textwidth}{!}{%
\begin{tabular}{c l c c c}
\toprule
 & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
\midrule

% ===== lambda = 0.00 =====
\multirow{5}{*}{\rotatebox{90}{$\lambda = 0.00$}}
& Discrete Uncertainty
& 17.19 & [16.60, 17.97] & 291.86 \\

\rowcolor{gray!15}
& Budgeted Uncertainty
& \downarrowmark\;15.77 \;\downarrowmark
& [15.18, 16.10]
& \downarrowmark\;49.30 \;\downarrowmark \\


& D* Lite
& 18.05 & [17.38, 18.92] & 232.22 \\

& D* Lite w.\ Discrete guidance
& 16.28 & [15.41, 17.00] & 232.12 \\

& D* Lite w.\ Budgeted guidance
& 15.24 & [14.57, 15.95] & 231.65 \\

\midrule

% ===== lambda = 0.10 (baseline) =====
\multirow{5}{*}{%
\rotatebox{90}{$\lambda = 0.10^{\ast}$}
}
& Discrete Uncertainty
& 17.19 & [16.55, 17.98] & 287.55 \\

& Budgeted Uncertainty
& 17.04 & [16.37, 17.35] & 85.43 \\

& D* Lite
& 18.05 & [17.38, 18.92] & 230.96 \\

& D* Lite w.\ Discrete guidance
& 16.28 & [15.33, 17.00] & 231.38 \\

& D* Lite w.\ Budgeted guidance
& 15.33 & [14.57, 16.12] & 231.29 \\

\midrule

% ===== lambda = 0.25 =====
\multirow{5}{*}{\rotatebox{90}{$\lambda = 0.25$}}
& Discrete Uncertainty
& 17.19 & [16.60, 17.96] & 287.01 \\

\rowcolor{gray!15}
& Budgeted Uncertainty
& \uparrowmark\;18.25 \;\uparrowmark
& [17.74, 18.75]
& \uparrowmark\;433.59 \;\uparrowmark \\

& D* Lite
& 18.05 & [17.38, 18.90] & 235.27 \\

& D* Lite w.\ Discrete guidance
& 16.28 & [15.33, 17.05] & 234.16 \\

& D* Lite w.\ Budgeted guidance
& 15.59 & [14.63, 16.28] & 233.42 \\

\midrule

% ===== lambda = 0.50 =====
\multirow{5}{*}{\rotatebox{90}{$\lambda = 0.50$}}
& Discrete Uncertainty
& 17.19 & [16.60, 17.98] & 315.02 \\

& Budgeted Uncertainty
& 19.73 & [19.31, 20.32] & 3415.74 \\

& D* Lite
& 18.05 & [17.38, 18.90] & 313.06 \\

& D* Lite w.\ Discrete guidance
& 16.28 & [15.42, 17.05] & 268.97 \\

& D* Lite w.\ Budgeted guidance
& 15.75 & [15.14, 16.53] & 254.03 \\

\midrule

% ===== lambda = 1.00 =====
\multirow{5}{*}{\rotatebox{90}{$\lambda = 1.00$}}
& Discrete Uncertainty
& 17.19 & [16.55, 17.97] & 323.56 \\

& Budgeted Uncertainty
& 21.64 & [21.00, 22.02] & 45773.08 \\

& D* Lite
& 18.05 & [17.36, 18.92] & 333.87 \\

& D* Lite w.\ Discrete guidance
& 16.28 & [15.32, 17.07] & 273.82 \\

& D* Lite w.\ Budgeted guidance
& 15.75 & [15.15, 16.59] & 257.00 \\

\bottomrule
\end{tabular}
}
\vspace{0.3em}
\footnotesize
$\ast$ Baseline configuration.
\end{table}








\newpage


  \section{Experiment 6: Number of Beacons}
    In this experiment, we study the effect of milestone-based replanning frequency by
    varying the number of beacons used during execution. Increasing the number of beacons
    corresponds to more frequent replanning opportunities along the path.

    \begin{table}[htbp]
      \centering
      \label{tab:param-variations-beacons}
          \begin{tabular}{lll}
          \toprule
          \textbf{Parameter} & \textbf{Baseline} & \textbf{Tested values} \\
          \midrule
          Number of beacons & 5 & $\{1, 5, 20\}$ \\
          \bottomrule
          \end{tabular}
      \caption{Experiment 8: Parameter variations relative to the baseline configuration}
    \end{table}

    \begin{table}[htbp]
    \centering
    \caption{Performance comparison across beacon counts}
    \label{tab:number-of-beacons}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c}
    \toprule
    & Algorithm & Cost (median) & 95\% CI & Runtime (ms, median) \\
    \midrule

    % ===== beacons = 1 =====
    \multirow{5}{*}{\rotatebox{90}{1 Beacon}}
    & Discrete Uncertainty
    & 17.19 & [16.60, 17.98] & 282.84 \\

    & Budgeted Uncertainty
    & 17.04 & [16.46, 17.35] & 85.14 \\

    & D* Lite
    & 18.05 & [17.38, 18.90] & 229.52 \\

    & D* Lite w.\ Discrete guidance
    & 16.80 & [16.04, 17.65] & 229.42 \\

    & D* Lite w.\ Budgeted guidance
    & 16.35 & [15.81, 17.35] & 229.04 \\

    \midrule

    % ===== beacons = 5 (baseline) =====
    \multirow{5}{*}{\rotatebox{90}{5$^{\ast}$ Beacons}}
    & Discrete Uncertainty
    & 17.19 & [16.48, 17.97] & 276.43 \\

    & Budgeted Uncertainty
    & 17.04 & [16.40, 17.34] & 83.11 \\

    & D* Lite
    & 18.05 & [17.36, 18.90] & 226.48 \\

    & D* Lite w.\ Discrete guidance
    & 15.92 & [15.01, 16.72] & 224.72 \\

    & D* Lite w.\ Budgeted guidance
    & 15.39 & [14.54, 16.28] & 224.59 \\

    \midrule

    % ===== beacons = 20 =====
    \multirow{5}{*}{\rotatebox{90}{20 Becons}}
    & Discrete Uncertainty
    & 17.19 & [16.60, 17.97] & 279.12 \\

    & Budgeted Uncertainty
    & 17.04 & [16.40, 17.35] & 83.22 \\

    & D* Lite
    & 18.05 & [17.38, 18.88] & 227.46 \\

    & D* Lite w.\ Discrete guidance
    & 16.45 & [15.51, 17.14] & 227.22 \\

    & D* Lite w.\ Budgeted guidance
    & 15.57 & [14.64, 16.29] & 226.85 \\

    \bottomrule
    \end{tabular}
    }
    \vspace{0.3em}
    \footnotesize
    $\ast$ Baseline configuration.
    \end{table}

\newpage


\chapter{CONCLUSION}
    Our experiments show that combining robust combinatorial optimization handling uncertainty via uncertainty sets can be used 
    for mobile robot path finding to a certain degree.

    One possible adaptation that we find worth looking into in future research is robust optimization for smaller scenarios/ windows.
    For example, imagine an evironment with environmental sensors placed on "hotspots".
    We could map sensor data as costs on an unstructured grid and use this real time data as possible waypoints for a coupled-D*Lite approach.
    A robust combinatorial optimization method could be used beforehand to make out the best possible route using these possible waypoints
    to give a rough estimate route for D* Lite to then traverse through.



\bibliographystyle{alpha}
\bibliography{literature}



\chapter{APPENDIX}
\label{chap:appendix}
\section{Geostatistical Formulations}
\begin{equation}
\gamma(r)
=
\sigma^2 \left( 1 - \operatorname{cor}\!\left( s \cdot \frac{r}{\ell} \right) \right)
+ n,
\label{eq:variogram}
\end{equation}

\begin{equation}
  C(r)
  =
  \sigma^2 \, \operatorname{cor}\!\left( s \cdot \frac{r}{\ell} \right),
  \label{eq:covariance}
\end{equation}

\begin{equation}
\rho(r)
=
\operatorname{cor}\!\left( s \cdot \frac{r}{\ell} \right).
\label{eq:correlation}
\end{equation}







\begin{table}[htbp]
\centering
\caption{Predefined covariance models in GSTools \cite{muller2022}.}
\label{tab:gstools-covariance-models}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{l p{7.5cm} l}
\toprule
\textbf{Model} & $\boldsymbol{\mathrm{cor}(h)}$ & \textbf{Source} \\
\midrule
Gaussian &
$\exp(-h^2)$ &
Webster and Oliver (2007) \\

Exponential &
$\exp(-h)$ &
Webster and Oliver (2007) \\

Stable &
$\exp(-h^\alpha)$ &
Wackernagel (2003) \\

Mat\'ern &
$\dfrac{2^{1-\nu}}{\Gamma(\nu)} \, (\sqrt{\nu}\,h)^\nu \cdot K_\nu(\sqrt{\nu}\,h)$ &
Rasmussen and Williams (2005) \\

Rational &
$\left(1 + \dfrac{h^2}{\alpha}\right)^{-\alpha}$ &
Rasmussen and Williams (2005) \\

Cubic &
$\left(1 - 7h^2 + \dfrac{35}{4}h^3 - \dfrac{7}{2}h^5 + \dfrac{3}{4}h^7 \right) \quad (h < 1)$ &
Chil\`es and Delfiner (2012) \\

Linear &
$(1 - h) \quad (h < 1)$ &
Webster and Oliver (2007) \\

Circular &
$\dfrac{2}{\pi} \left( \cos^{-1}(h) - h \sqrt{1 - h^2} \right) \quad (h < 1)$ &
Webster and Oliver (2007) \\

Spherical &
$\left(1 - \dfrac{3}{2}h + \dfrac{1}{2}h^3 \right) \quad (h < 1)$ &
Webster and Oliver (2007) \\

HyperSpherical &
$\left(
1 - h \cdot
\dfrac{{}_2F_1\!\left(\tfrac{1}{2},-\tfrac{d-1}{2},\tfrac{3}{2},h^2\right)}
{{}_2F_1\!\left(\tfrac{1}{2},-\tfrac{d-1}{2},\tfrac{3}{2},1\right)}
\right) \quad (h < 1)$ &
Mat\'ern (1960) \\

SuperSpherical &
$\left(
1 - h \cdot
\dfrac{{}_2F_1\!\left(\tfrac{1}{2},-\nu,\tfrac{3}{2},h^2\right)}
{{}_2F_1\!\left(\tfrac{1}{2},-\nu,\tfrac{3}{2},1\right)}
\right) \quad (h < 1)$ &
Mat\'ern (1960) \\

JBessel &
$\Gamma(\nu + 1) \cdot \left(\dfrac{h}{2}\right)^{-\nu} \cdot J_\nu(h)$ &
Chil\`es and Delfiner (2012) \\

TPLSimple &
$(1 - h)^\nu \quad (h < 1)$ &
Wendland (1995) \\

TPLGaussian &
$H \cdot E_{1+H}(h^2)$ &
Di Federico and Neuman (1997) \\

TPLExponential &
$2H \cdot E_{1+2H}(h)$ &
Di Federico and Neuman (1997) \\

TPLStable &
$\dfrac{2H}{\alpha} \cdot E_{1+\frac{2H}{\alpha}}(h^\alpha)$ &
M\"uller et al. (2021a) \\
\bottomrule
\end{tabular}

\vspace{0.3cm}
\footnotesize
Formulas including the subscript $(h < 1)$ are piecewise-defined functions being constantly zero for $h > 1$.
Here, $h$ is the non-dimensional distance, $d$ is the dimension,
$\Gamma(x)$ is the gamma function,
$K_\nu(x)$ is the modified Bessel function of the second kind,
$J_\nu(x)$ is the Bessel function of the first kind,
${}_2F_1(a,b,c,x)$ is the ordinary hypergeometric function, and
$E_\nu(x)$ is the exponential integral function (Abramowitz et al., 1972).
All other variables are shape parameters of the respective models.
\end{table}

\begin{equation}
h
=
\sqrt{
\sum_{i=1}^{d}
\left( \frac{r_i}{\ell_i} \right)^2
},
\label{eq:anisotropic_metric}
\end{equation}

\begin{equation}
h(x,y,\tau)
=
\sqrt{
\left( \frac{\Delta p}{\ell_p} \right)^2
+
\left( \frac{\Delta q}{\ell_q} \right)^2
+
\left( \frac{\Delta \tau}{\ell_t} \right)^2
}.
\label{eq:metric_xyz}
\end{equation}

\begin{equation}
C_m(\mathbf{r}, \Delta \tau)
=
C\!\left(
\sqrt{
\sum_{i=1}^{2}
\left( \frac{r_i}{\ell_i} \right)^2
+
\left( \frac{\Delta \tau}{\ell_t} \right)^2
}
\right),
\label{eq:metric_spatiotemporal}
\end{equation}
where $\mathbf{r} = (x-x', y-y')$ and $\Delta \tau = \tau - \tau'$.


\begin{equation}
U(\mathbf{x})
=
\sqrt{\frac{\sigma^2}{N}}
\sum_{i=1}^{N}
\left(
Z_{1,i} \cos(\mathbf{k}_i \cdot \mathbf{x})
+
Z_{2,i} \sin(\mathbf{k}_i \cdot \mathbf{x})
\right),
\label{eq:srf_generation}
\end{equation}
where $Z_{1,i}, Z_{2,i} \sim \mathcal{N}(0,1)$ are independent standard normal
variables and $\mathbf{k}_i \in \mathbb{R}^3$ are wave vectors sampled from the
spectral density associated with the covariance model~\ref{eq:covariance}.


\end{document}
